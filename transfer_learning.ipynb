{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('X.npy')\n",
    "Y = np.load('Y.npy')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1649, 64, 64, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train_empty = np.empty((X_train.shape[0], X_train.shape[1], X_train.shape[2], 3))\n",
    "# X_test_empty = np.empty((X_test.shape[0], X_test.shape[1], X_test.shape[2], 3))\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "\n",
    "X_train = np.broadcast_to(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2], 3))\n",
    "X_test = np.broadcast_to(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[2], 3))\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "vggmodel = VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layers in (vggmodel.layers)[:19]:\n",
    "    layers.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train = vggmodel.predict(X_train)\n",
    "new_X_test = vggmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1649, 2, 2, 512)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "\n",
    "model_final = Sequential()\n",
    "model_final.add(Flatten(input_shape=(2, 2, 512)))\n",
    "model_final.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 20,490\n",
      "Trainable params: 20,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1649 samples, validate on 413 samples\n",
      "Epoch 1/1000\n",
      "1649/1649 [==============================] - 1s 728us/step - loss: 2.3492 - acc: 0.1098 - val_loss: 2.2672 - val_acc: 0.1622\n",
      "Epoch 2/1000\n",
      "1649/1649 [==============================] - 0s 198us/step - loss: 2.2518 - acc: 0.1662 - val_loss: 2.2083 - val_acc: 0.2542\n",
      "Epoch 3/1000\n",
      "1649/1649 [==============================] - 0s 202us/step - loss: 2.1914 - acc: 0.2511 - val_loss: 2.1507 - val_acc: 0.3148\n",
      "Epoch 4/1000\n",
      "1649/1649 [==============================] - 0s 236us/step - loss: 2.1323 - acc: 0.3190 - val_loss: 2.0991 - val_acc: 0.3196\n",
      "Epoch 5/1000\n",
      "1649/1649 [==============================] - 0s 202us/step - loss: 2.0769 - acc: 0.3675 - val_loss: 2.0427 - val_acc: 0.3995\n",
      "Epoch 6/1000\n",
      "1649/1649 [==============================] - 0s 187us/step - loss: 2.0248 - acc: 0.4057 - val_loss: 1.9960 - val_acc: 0.4625\n",
      "Epoch 7/1000\n",
      "1649/1649 [==============================] - 0s 194us/step - loss: 1.9760 - acc: 0.4621 - val_loss: 1.9492 - val_acc: 0.4722\n",
      "Epoch 8/1000\n",
      "1649/1649 [==============================] - 0s 188us/step - loss: 1.9313 - acc: 0.4754 - val_loss: 1.9032 - val_acc: 0.5012\n",
      "Epoch 9/1000\n",
      "1649/1649 [==============================] - 0s 203us/step - loss: 1.8857 - acc: 0.5143 - val_loss: 1.8719 - val_acc: 0.5230\n",
      "Epoch 10/1000\n",
      "1649/1649 [==============================] - 0s 197us/step - loss: 1.8442 - acc: 0.5446 - val_loss: 1.8307 - val_acc: 0.5230\n",
      "Epoch 11/1000\n",
      "1649/1649 [==============================] - 0s 207us/step - loss: 1.8053 - acc: 0.5609 - val_loss: 1.7933 - val_acc: 0.5666\n",
      "Epoch 12/1000\n",
      "1649/1649 [==============================] - 0s 209us/step - loss: 1.7694 - acc: 0.5664 - val_loss: 1.7589 - val_acc: 0.5835\n",
      "Epoch 13/1000\n",
      "1649/1649 [==============================] - 0s 190us/step - loss: 1.7341 - acc: 0.5901 - val_loss: 1.7268 - val_acc: 0.6005\n",
      "Epoch 14/1000\n",
      "1649/1649 [==============================] - 0s 193us/step - loss: 1.7011 - acc: 0.6010 - val_loss: 1.6983 - val_acc: 0.5714\n",
      "Epoch 15/1000\n",
      "1649/1649 [==============================] - 0s 200us/step - loss: 1.6703 - acc: 0.6095 - val_loss: 1.6685 - val_acc: 0.6247\n",
      "Epoch 16/1000\n",
      "1649/1649 [==============================] - 0s 188us/step - loss: 1.6404 - acc: 0.6210 - val_loss: 1.6432 - val_acc: 0.5884\n",
      "Epoch 17/1000\n",
      "1649/1649 [==============================] - 0s 193us/step - loss: 1.6117 - acc: 0.6270 - val_loss: 1.6124 - val_acc: 0.6174\n",
      "Epoch 18/1000\n",
      "1649/1649 [==============================] - 0s 193us/step - loss: 1.5855 - acc: 0.6374 - val_loss: 1.5925 - val_acc: 0.6053\n",
      "Epoch 19/1000\n",
      "1649/1649 [==============================] - 0s 198us/step - loss: 1.5614 - acc: 0.6416 - val_loss: 1.5713 - val_acc: 0.6295\n",
      "Epoch 20/1000\n",
      "1649/1649 [==============================] - 0s 190us/step - loss: 1.5356 - acc: 0.6604 - val_loss: 1.5435 - val_acc: 0.6441\n",
      "Epoch 21/1000\n",
      "1649/1649 [==============================] - 0s 198us/step - loss: 1.5127 - acc: 0.6555 - val_loss: 1.5184 - val_acc: 0.6755\n",
      "Epoch 22/1000\n",
      "1649/1649 [==============================] - 0s 203us/step - loss: 1.4904 - acc: 0.6743 - val_loss: 1.5014 - val_acc: 0.6489\n",
      "Epoch 23/1000\n",
      "1649/1649 [==============================] - 0s 181us/step - loss: 1.4689 - acc: 0.6725 - val_loss: 1.4803 - val_acc: 0.6731\n",
      "Epoch 24/1000\n",
      "1649/1649 [==============================] - 0s 192us/step - loss: 1.4502 - acc: 0.6901 - val_loss: 1.4598 - val_acc: 0.6707\n",
      "Epoch 25/1000\n",
      "1649/1649 [==============================] - 0s 237us/step - loss: 1.4292 - acc: 0.6883 - val_loss: 1.4427 - val_acc: 0.6828\n",
      "Epoch 26/1000\n",
      "1649/1649 [==============================] - 0s 264us/step - loss: 1.4099 - acc: 0.6907 - val_loss: 1.4258 - val_acc: 0.6755\n",
      "Epoch 27/1000\n",
      "1649/1649 [==============================] - 0s 255us/step - loss: 1.3926 - acc: 0.7010 - val_loss: 1.4114 - val_acc: 0.6659\n",
      "Epoch 28/1000\n",
      "1649/1649 [==============================] - 0s 237us/step - loss: 1.3762 - acc: 0.7089 - val_loss: 1.3941 - val_acc: 0.6804\n",
      "Epoch 29/1000\n",
      "1649/1649 [==============================] - 0s 226us/step - loss: 1.3582 - acc: 0.7095 - val_loss: 1.3786 - val_acc: 0.6852\n",
      "Epoch 30/1000\n",
      "1649/1649 [==============================] - 0s 234us/step - loss: 1.3436 - acc: 0.7107 - val_loss: 1.3619 - val_acc: 0.6780\n",
      "Epoch 31/1000\n",
      "1649/1649 [==============================] - 0s 209us/step - loss: 1.3275 - acc: 0.7089 - val_loss: 1.3485 - val_acc: 0.6828\n",
      "Epoch 32/1000\n",
      "1649/1649 [==============================] - 0s 203us/step - loss: 1.3129 - acc: 0.7174 - val_loss: 1.3310 - val_acc: 0.7022\n",
      "Epoch 33/1000\n",
      "1649/1649 [==============================] - 0s 198us/step - loss: 1.2977 - acc: 0.7259 - val_loss: 1.3203 - val_acc: 0.6901\n",
      "Epoch 34/1000\n",
      "1649/1649 [==============================] - 0s 190us/step - loss: 1.2845 - acc: 0.7210 - val_loss: 1.3102 - val_acc: 0.6973\n",
      "Epoch 35/1000\n",
      "1649/1649 [==============================] - 0s 203us/step - loss: 1.2703 - acc: 0.7235 - val_loss: 1.2937 - val_acc: 0.6925\n",
      "Epoch 36/1000\n",
      "1649/1649 [==============================] - 0s 235us/step - loss: 1.2583 - acc: 0.7253 - val_loss: 1.2838 - val_acc: 0.7046\n",
      "Epoch 37/1000\n",
      "1649/1649 [==============================] - 0s 229us/step - loss: 1.2451 - acc: 0.7295 - val_loss: 1.2690 - val_acc: 0.7191\n",
      "Epoch 38/1000\n",
      "1649/1649 [==============================] - 0s 189us/step - loss: 1.2332 - acc: 0.7277 - val_loss: 1.2581 - val_acc: 0.7167\n",
      "Epoch 39/1000\n",
      "1649/1649 [==============================] - 0s 201us/step - loss: 1.2222 - acc: 0.7332 - val_loss: 1.2432 - val_acc: 0.7215\n",
      "Epoch 40/1000\n",
      "1649/1649 [==============================] - 0s 190us/step - loss: 1.2090 - acc: 0.7398 - val_loss: 1.2357 - val_acc: 0.7119\n",
      "Epoch 41/1000\n",
      "1649/1649 [==============================] - 0s 172us/step - loss: 1.1991 - acc: 0.7344 - val_loss: 1.2297 - val_acc: 0.7022\n",
      "Epoch 42/1000\n",
      "1649/1649 [==============================] - 0s 198us/step - loss: 1.1868 - acc: 0.7556 - val_loss: 1.2183 - val_acc: 0.7022\n",
      "Epoch 43/1000\n",
      "1649/1649 [==============================] - 0s 191us/step - loss: 1.1767 - acc: 0.7453 - val_loss: 1.2059 - val_acc: 0.7167\n",
      "Epoch 44/1000\n",
      "1649/1649 [==============================] - 0s 202us/step - loss: 1.1676 - acc: 0.7520 - val_loss: 1.1963 - val_acc: 0.7264\n",
      "Epoch 45/1000\n",
      "1649/1649 [==============================] - 0s 226us/step - loss: 1.1573 - acc: 0.7495 - val_loss: 1.1841 - val_acc: 0.7264\n",
      "Epoch 46/1000\n",
      "1649/1649 [==============================] - 0s 194us/step - loss: 1.1487 - acc: 0.7568 - val_loss: 1.1754 - val_acc: 0.7240\n",
      "Epoch 47/1000\n",
      "1649/1649 [==============================] - 0s 210us/step - loss: 1.1374 - acc: 0.7538 - val_loss: 1.1677 - val_acc: 0.7288\n",
      "Epoch 48/1000\n",
      "1649/1649 [==============================] - 0s 237us/step - loss: 1.1295 - acc: 0.7489 - val_loss: 1.1611 - val_acc: 0.7385\n",
      "Epoch 49/1000\n",
      "1649/1649 [==============================] - 0s 207us/step - loss: 1.1197 - acc: 0.7556 - val_loss: 1.1485 - val_acc: 0.7385\n",
      "Epoch 50/1000\n",
      "1649/1649 [==============================] - 0s 224us/step - loss: 1.1116 - acc: 0.7677 - val_loss: 1.1426 - val_acc: 0.7337\n",
      "Epoch 51/1000\n",
      "1649/1649 [==============================] - 0s 233us/step - loss: 1.1035 - acc: 0.7544 - val_loss: 1.1311 - val_acc: 0.7337\n",
      "Epoch 52/1000\n",
      "1649/1649 [==============================] - 0s 224us/step - loss: 1.0951 - acc: 0.7738 - val_loss: 1.1295 - val_acc: 0.7337\n",
      "Epoch 53/1000\n",
      "1649/1649 [==============================] - 0s 237us/step - loss: 1.0865 - acc: 0.7690 - val_loss: 1.1210 - val_acc: 0.7240\n",
      "Epoch 54/1000\n",
      "1649/1649 [==============================] - 0s 212us/step - loss: 1.0801 - acc: 0.7635 - val_loss: 1.1126 - val_acc: 0.7385\n",
      "Epoch 55/1000\n",
      "1649/1649 [==============================] - 0s 228us/step - loss: 1.0724 - acc: 0.7683 - val_loss: 1.1053 - val_acc: 0.7288\n",
      "Epoch 56/1000\n",
      "1649/1649 [==============================] - 0s 224us/step - loss: 1.0631 - acc: 0.7635 - val_loss: 1.0970 - val_acc: 0.7458\n",
      "Epoch 57/1000\n",
      "1649/1649 [==============================] - 0s 225us/step - loss: 1.0559 - acc: 0.7732 - val_loss: 1.0918 - val_acc: 0.7361\n",
      "Epoch 58/1000\n",
      "1649/1649 [==============================] - 0s 206us/step - loss: 1.0477 - acc: 0.7714 - val_loss: 1.0793 - val_acc: 0.7458\n",
      "Epoch 59/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1649/1649 [==============================] - 0s 226us/step - loss: 1.0424 - acc: 0.7799 - val_loss: 1.0765 - val_acc: 0.7385\n",
      "Epoch 60/1000\n",
      "1649/1649 [==============================] - 0s 195us/step - loss: 1.0355 - acc: 0.7780 - val_loss: 1.0698 - val_acc: 0.7458\n",
      "Epoch 61/1000\n",
      "1649/1649 [==============================] - 0s 193us/step - loss: 1.0279 - acc: 0.7859 - val_loss: 1.0642 - val_acc: 0.7458\n",
      "Epoch 62/1000\n",
      "1649/1649 [==============================] - 0s 203us/step - loss: 1.0218 - acc: 0.7708 - val_loss: 1.0564 - val_acc: 0.7554\n",
      "Epoch 63/1000\n",
      "1649/1649 [==============================] - 0s 198us/step - loss: 1.0146 - acc: 0.7799 - val_loss: 1.0508 - val_acc: 0.7530\n",
      "Epoch 64/1000\n",
      "1649/1649 [==============================] - 0s 200us/step - loss: 1.0085 - acc: 0.7811 - val_loss: 1.0430 - val_acc: 0.7627\n",
      "Epoch 65/1000\n",
      "1649/1649 [==============================] - 0s 195us/step - loss: 1.0032 - acc: 0.7817 - val_loss: 1.0389 - val_acc: 0.7482\n",
      "Epoch 66/1000\n",
      "1649/1649 [==============================] - 0s 202us/step - loss: 0.9972 - acc: 0.7805 - val_loss: 1.0331 - val_acc: 0.7482\n",
      "Epoch 67/1000\n",
      "1649/1649 [==============================] - 0s 196us/step - loss: 0.9897 - acc: 0.7817 - val_loss: 1.0284 - val_acc: 0.7554\n",
      "Epoch 68/1000\n",
      "1649/1649 [==============================] - 0s 204us/step - loss: 0.9842 - acc: 0.7823 - val_loss: 1.0188 - val_acc: 0.7627\n",
      "Epoch 69/1000\n",
      "1649/1649 [==============================] - 0s 198us/step - loss: 0.9797 - acc: 0.7835 - val_loss: 1.0109 - val_acc: 0.7748\n",
      "Epoch 70/1000\n",
      "1649/1649 [==============================] - 0s 219us/step - loss: 0.9735 - acc: 0.7884 - val_loss: 1.0099 - val_acc: 0.7554\n",
      "Epoch 71/1000\n",
      "1649/1649 [==============================] - 0s 287us/step - loss: 0.9676 - acc: 0.7920 - val_loss: 1.0046 - val_acc: 0.7651\n",
      "Epoch 72/1000\n",
      "1649/1649 [==============================] - 0s 263us/step - loss: 0.9611 - acc: 0.7902 - val_loss: 0.9983 - val_acc: 0.7676\n",
      "Epoch 73/1000\n",
      "1649/1649 [==============================] - 0s 258us/step - loss: 0.9563 - acc: 0.7920 - val_loss: 0.9926 - val_acc: 0.7676\n",
      "Epoch 74/1000\n",
      "1649/1649 [==============================] - 0s 202us/step - loss: 0.9515 - acc: 0.7890 - val_loss: 0.9895 - val_acc: 0.7603\n",
      "Epoch 75/1000\n",
      "1649/1649 [==============================] - 0s 296us/step - loss: 0.9472 - acc: 0.7847 - val_loss: 0.9826 - val_acc: 0.7772\n",
      "Epoch 76/1000\n",
      "1649/1649 [==============================] - 0s 211us/step - loss: 0.9404 - acc: 0.7968 - val_loss: 0.9785 - val_acc: 0.7724\n",
      "Epoch 77/1000\n",
      "1649/1649 [==============================] - 0s 195us/step - loss: 0.9370 - acc: 0.7932 - val_loss: 0.9717 - val_acc: 0.7700\n",
      "Epoch 78/1000\n",
      "1649/1649 [==============================] - 0s 209us/step - loss: 0.9309 - acc: 0.7932 - val_loss: 0.9693 - val_acc: 0.7676\n",
      "Epoch 79/1000\n",
      "1649/1649 [==============================] - 0s 219us/step - loss: 0.9259 - acc: 0.7999 - val_loss: 0.9639 - val_acc: 0.7797\n",
      "Epoch 80/1000\n",
      "1649/1649 [==============================] - 0s 204us/step - loss: 0.9214 - acc: 0.7926 - val_loss: 0.9596 - val_acc: 0.7797\n",
      "Epoch 81/1000\n",
      "1649/1649 [==============================] - 0s 210us/step - loss: 0.9161 - acc: 0.8011 - val_loss: 0.9549 - val_acc: 0.7821\n",
      "Epoch 82/1000\n",
      "1649/1649 [==============================] - 0s 225us/step - loss: 0.9115 - acc: 0.7975 - val_loss: 0.9520 - val_acc: 0.7724\n",
      "Epoch 83/1000\n",
      "1649/1649 [==============================] - 0s 206us/step - loss: 0.9076 - acc: 0.7968 - val_loss: 0.9498 - val_acc: 0.7651\n",
      "Epoch 84/1000\n",
      "1649/1649 [==============================] - 0s 207us/step - loss: 0.9037 - acc: 0.7944 - val_loss: 0.9404 - val_acc: 0.7748\n",
      "Epoch 85/1000\n",
      "1649/1649 [==============================] - 0s 206us/step - loss: 0.8988 - acc: 0.7981 - val_loss: 0.9373 - val_acc: 0.7748\n",
      "Epoch 86/1000\n",
      "1649/1649 [==============================] - 0s 225us/step - loss: 0.8938 - acc: 0.7962 - val_loss: 0.9318 - val_acc: 0.7772\n",
      "Epoch 87/1000\n",
      "1649/1649 [==============================] - 0s 221us/step - loss: 0.8897 - acc: 0.8011 - val_loss: 0.9270 - val_acc: 0.7797\n",
      "Epoch 88/1000\n",
      "1649/1649 [==============================] - 0s 222us/step - loss: 0.8855 - acc: 0.8023 - val_loss: 0.9281 - val_acc: 0.7700\n",
      "Epoch 89/1000\n",
      "1649/1649 [==============================] - 0s 227us/step - loss: 0.8814 - acc: 0.8053 - val_loss: 0.9231 - val_acc: 0.7748\n",
      "Epoch 90/1000\n",
      "1649/1649 [==============================] - 0s 216us/step - loss: 0.8778 - acc: 0.7987 - val_loss: 0.9195 - val_acc: 0.7797\n",
      "Epoch 91/1000\n",
      "1649/1649 [==============================] - 0s 233us/step - loss: 0.8743 - acc: 0.8029 - val_loss: 0.9140 - val_acc: 0.7772\n",
      "Epoch 92/1000\n",
      "1649/1649 [==============================] - 0s 237us/step - loss: 0.8707 - acc: 0.8053 - val_loss: 0.9120 - val_acc: 0.7845\n",
      "Epoch 93/1000\n",
      "1649/1649 [==============================] - 0s 237us/step - loss: 0.8660 - acc: 0.8035 - val_loss: 0.9055 - val_acc: 0.7869\n",
      "Epoch 94/1000\n",
      "1649/1649 [==============================] - 0s 233us/step - loss: 0.8615 - acc: 0.8102 - val_loss: 0.9027 - val_acc: 0.7797\n",
      "Epoch 95/1000\n",
      "1649/1649 [==============================] - 0s 230us/step - loss: 0.8583 - acc: 0.8023 - val_loss: 0.8993 - val_acc: 0.7845\n",
      "Epoch 96/1000\n",
      "1649/1649 [==============================] - 0s 259us/step - loss: 0.8540 - acc: 0.8053 - val_loss: 0.8950 - val_acc: 0.7869\n",
      "Epoch 97/1000\n",
      "1649/1649 [==============================] - 0s 230us/step - loss: 0.8506 - acc: 0.8090 - val_loss: 0.8903 - val_acc: 0.7869\n",
      "Epoch 98/1000\n",
      "1649/1649 [==============================] - 0s 225us/step - loss: 0.8466 - acc: 0.8084 - val_loss: 0.8886 - val_acc: 0.7918\n",
      "Epoch 99/1000\n",
      "1649/1649 [==============================] - 0s 218us/step - loss: 0.8436 - acc: 0.8102 - val_loss: 0.8837 - val_acc: 0.7845\n",
      "Epoch 100/1000\n",
      "1649/1649 [==============================] - 0s 241us/step - loss: 0.8403 - acc: 0.8078 - val_loss: 0.8831 - val_acc: 0.7748\n",
      "Epoch 101/1000\n",
      "1649/1649 [==============================] - 0s 240us/step - loss: 0.8366 - acc: 0.8090 - val_loss: 0.8762 - val_acc: 0.7942\n",
      "Epoch 102/1000\n",
      "1649/1649 [==============================] - 0s 231us/step - loss: 0.8339 - acc: 0.8126 - val_loss: 0.8760 - val_acc: 0.7845\n",
      "Epoch 103/1000\n",
      "1649/1649 [==============================] - 0s 232us/step - loss: 0.8293 - acc: 0.8114 - val_loss: 0.8712 - val_acc: 0.7918\n",
      "Epoch 104/1000\n",
      "1649/1649 [==============================] - 0s 207us/step - loss: 0.8251 - acc: 0.8102 - val_loss: 0.8704 - val_acc: 0.7918\n",
      "Epoch 105/1000\n",
      "1649/1649 [==============================] - 0s 237us/step - loss: 0.8230 - acc: 0.8132 - val_loss: 0.8654 - val_acc: 0.7942\n",
      "Epoch 106/1000\n",
      "1649/1649 [==============================] - 0s 234us/step - loss: 0.8196 - acc: 0.8102 - val_loss: 0.8595 - val_acc: 0.7966\n",
      "Epoch 107/1000\n",
      "1649/1649 [==============================] - 0s 233us/step - loss: 0.8163 - acc: 0.8138 - val_loss: 0.8583 - val_acc: 0.7918\n",
      "Epoch 108/1000\n",
      "1649/1649 [==============================] - 0s 224us/step - loss: 0.8132 - acc: 0.8138 - val_loss: 0.8567 - val_acc: 0.7942\n",
      "Epoch 109/1000\n",
      "1649/1649 [==============================] - 0s 227us/step - loss: 0.8104 - acc: 0.8090 - val_loss: 0.8531 - val_acc: 0.7942\n",
      "Epoch 110/1000\n",
      "1649/1649 [==============================] - 0s 229us/step - loss: 0.8067 - acc: 0.8150 - val_loss: 0.8491 - val_acc: 0.7990\n",
      "Epoch 111/1000\n",
      "1649/1649 [==============================] - 0s 222us/step - loss: 0.8038 - acc: 0.8169 - val_loss: 0.8462 - val_acc: 0.7942\n",
      "Epoch 112/1000\n",
      "1649/1649 [==============================] - 0s 273us/step - loss: 0.8005 - acc: 0.8223 - val_loss: 0.8453 - val_acc: 0.7893\n",
      "Epoch 113/1000\n",
      "1649/1649 [==============================] - 0s 288us/step - loss: 0.7987 - acc: 0.8169 - val_loss: 0.8403 - val_acc: 0.7966\n",
      "Epoch 114/1000\n",
      "1649/1649 [==============================] - 0s 275us/step - loss: 0.7942 - acc: 0.8211 - val_loss: 0.8369 - val_acc: 0.8063\n",
      "Epoch 115/1000\n",
      "1649/1649 [==============================] - 0s 301us/step - loss: 0.7914 - acc: 0.8223 - val_loss: 0.8381 - val_acc: 0.8015\n",
      "Epoch 116/1000\n",
      "1649/1649 [==============================] - 0s 287us/step - loss: 0.7890 - acc: 0.8229 - val_loss: 0.8324 - val_acc: 0.8039\n",
      "Epoch 117/1000\n",
      "1649/1649 [==============================] - 0s 284us/step - loss: 0.7868 - acc: 0.8156 - val_loss: 0.8260 - val_acc: 0.8063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/1000\n",
      "1649/1649 [==============================] - 0s 207us/step - loss: 0.7833 - acc: 0.8175 - val_loss: 0.8290 - val_acc: 0.7966\n",
      "Epoch 119/1000\n",
      "1649/1649 [==============================] - 0s 195us/step - loss: 0.7798 - acc: 0.8290 - val_loss: 0.8210 - val_acc: 0.8063\n",
      "Epoch 120/1000\n",
      "1649/1649 [==============================] - 0s 198us/step - loss: 0.7781 - acc: 0.8253 - val_loss: 0.8189 - val_acc: 0.8111\n",
      "Epoch 121/1000\n",
      "1649/1649 [==============================] - 0s 209us/step - loss: 0.7750 - acc: 0.8217 - val_loss: 0.8179 - val_acc: 0.8039\n",
      "Epoch 122/1000\n",
      "1649/1649 [==============================] - 0s 206us/step - loss: 0.7727 - acc: 0.8205 - val_loss: 0.8143 - val_acc: 0.8111\n",
      "Epoch 123/1000\n",
      "1649/1649 [==============================] - 0s 204us/step - loss: 0.7695 - acc: 0.8266 - val_loss: 0.8134 - val_acc: 0.8039\n",
      "Epoch 124/1000\n",
      "1649/1649 [==============================] - 0s 189us/step - loss: 0.7682 - acc: 0.8229 - val_loss: 0.8077 - val_acc: 0.8087\n",
      "Epoch 125/1000\n",
      "1649/1649 [==============================] - 0s 205us/step - loss: 0.7642 - acc: 0.8260 - val_loss: 0.8075 - val_acc: 0.8111\n",
      "Epoch 126/1000\n",
      "1649/1649 [==============================] - 0s 197us/step - loss: 0.7621 - acc: 0.8272 - val_loss: 0.8040 - val_acc: 0.8063\n",
      "Epoch 127/1000\n",
      "1649/1649 [==============================] - 0s 195us/step - loss: 0.7593 - acc: 0.8253 - val_loss: 0.8033 - val_acc: 0.8063\n",
      "Epoch 128/1000\n",
      "1649/1649 [==============================] - 0s 200us/step - loss: 0.7566 - acc: 0.8253 - val_loss: 0.8012 - val_acc: 0.8087\n",
      "Epoch 129/1000\n",
      "1649/1649 [==============================] - 0s 193us/step - loss: 0.7546 - acc: 0.8253 - val_loss: 0.7995 - val_acc: 0.8063\n",
      "Epoch 130/1000\n",
      "1649/1649 [==============================] - 0s 196us/step - loss: 0.7522 - acc: 0.8260 - val_loss: 0.7956 - val_acc: 0.8087\n",
      "Epoch 131/1000\n",
      "1649/1649 [==============================] - 0s 199us/step - loss: 0.7488 - acc: 0.8278 - val_loss: 0.7942 - val_acc: 0.8087\n",
      "Epoch 132/1000\n",
      "1649/1649 [==============================] - 0s 182us/step - loss: 0.7474 - acc: 0.8290 - val_loss: 0.7877 - val_acc: 0.8111\n",
      "Epoch 133/1000\n",
      "1649/1649 [==============================] - 0s 187us/step - loss: 0.7442 - acc: 0.8320 - val_loss: 0.7882 - val_acc: 0.8111\n",
      "Epoch 134/1000\n",
      "1649/1649 [==============================] - 0s 204us/step - loss: 0.7418 - acc: 0.8314 - val_loss: 0.7863 - val_acc: 0.8111\n",
      "Epoch 135/1000\n",
      "1649/1649 [==============================] - 0s 193us/step - loss: 0.7390 - acc: 0.8326 - val_loss: 0.7822 - val_acc: 0.8160\n",
      "Epoch 136/1000\n",
      "1649/1649 [==============================] - 0s 184us/step - loss: 0.7374 - acc: 0.8302 - val_loss: 0.7794 - val_acc: 0.8111\n",
      "Epoch 137/1000\n",
      "1649/1649 [==============================] - 0s 192us/step - loss: 0.7353 - acc: 0.8344 - val_loss: 0.7749 - val_acc: 0.8136\n",
      "Epoch 138/1000\n",
      "1649/1649 [==============================] - 0s 197us/step - loss: 0.7335 - acc: 0.8363 - val_loss: 0.7746 - val_acc: 0.8111\n",
      "Epoch 139/1000\n",
      "1649/1649 [==============================] - 0s 192us/step - loss: 0.7309 - acc: 0.8351 - val_loss: 0.7745 - val_acc: 0.8063\n",
      "Epoch 140/1000\n",
      "1649/1649 [==============================] - 0s 195us/step - loss: 0.7283 - acc: 0.8375 - val_loss: 0.7732 - val_acc: 0.8160\n",
      "Epoch 141/1000\n",
      "1649/1649 [==============================] - 0s 202us/step - loss: 0.7262 - acc: 0.8344 - val_loss: 0.7719 - val_acc: 0.8184\n",
      "Epoch 142/1000\n",
      "1649/1649 [==============================] - 0s 184us/step - loss: 0.7241 - acc: 0.8320 - val_loss: 0.7684 - val_acc: 0.8136\n",
      "Epoch 143/1000\n",
      "1649/1649 [==============================] - 0s 187us/step - loss: 0.7219 - acc: 0.8357 - val_loss: 0.7662 - val_acc: 0.8160\n",
      "Epoch 144/1000\n",
      "1649/1649 [==============================] - 0s 190us/step - loss: 0.7198 - acc: 0.8344 - val_loss: 0.7641 - val_acc: 0.8160\n",
      "Epoch 145/1000\n",
      "1649/1649 [==============================] - 0s 198us/step - loss: 0.7187 - acc: 0.8320 - val_loss: 0.7587 - val_acc: 0.8208\n",
      "Epoch 146/1000\n",
      "1649/1649 [==============================] - 0s 223us/step - loss: 0.7152 - acc: 0.8369 - val_loss: 0.7598 - val_acc: 0.8136\n",
      "Epoch 147/1000\n",
      "1649/1649 [==============================] - 0s 223us/step - loss: 0.7133 - acc: 0.8363 - val_loss: 0.7578 - val_acc: 0.8136\n",
      "Epoch 148/1000\n",
      "1649/1649 [==============================] - 0s 202us/step - loss: 0.7107 - acc: 0.8351 - val_loss: 0.7565 - val_acc: 0.8136\n",
      "Epoch 149/1000\n",
      "1649/1649 [==============================] - 0s 208us/step - loss: 0.7087 - acc: 0.8393 - val_loss: 0.7530 - val_acc: 0.8160\n",
      "Epoch 150/1000\n",
      "1649/1649 [==============================] - 0s 237us/step - loss: 0.7069 - acc: 0.8393 - val_loss: 0.7508 - val_acc: 0.8087\n",
      "Epoch 151/1000\n",
      "1649/1649 [==============================] - 0s 209us/step - loss: 0.7051 - acc: 0.8381 - val_loss: 0.7514 - val_acc: 0.8160\n",
      "Epoch 152/1000\n",
      "1649/1649 [==============================] - 0s 203us/step - loss: 0.7029 - acc: 0.8344 - val_loss: 0.7456 - val_acc: 0.8232\n",
      "Epoch 153/1000\n",
      "1649/1649 [==============================] - 0s 209us/step - loss: 0.7010 - acc: 0.8381 - val_loss: 0.7442 - val_acc: 0.8208\n",
      "Epoch 154/1000\n",
      "1649/1649 [==============================] - 0s 205us/step - loss: 0.6991 - acc: 0.8357 - val_loss: 0.7418 - val_acc: 0.8208\n",
      "Epoch 155/1000\n",
      "1649/1649 [==============================] - 0s 225us/step - loss: 0.6973 - acc: 0.8448 - val_loss: 0.7400 - val_acc: 0.8136\n",
      "Epoch 156/1000\n",
      "1649/1649 [==============================] - 0s 270us/step - loss: 0.6956 - acc: 0.8405 - val_loss: 0.7400 - val_acc: 0.8136\n",
      "Epoch 157/1000\n",
      "1649/1649 [==============================] - 0s 206us/step - loss: 0.6938 - acc: 0.8405 - val_loss: 0.7376 - val_acc: 0.8087\n",
      "Epoch 158/1000\n",
      "1649/1649 [==============================] - 0s 262us/step - loss: 0.6909 - acc: 0.8381 - val_loss: 0.7362 - val_acc: 0.8184\n",
      "Epoch 159/1000\n",
      "1649/1649 [==============================] - 1s 306us/step - loss: 0.6901 - acc: 0.8435 - val_loss: 0.7334 - val_acc: 0.8232\n",
      "Epoch 160/1000\n",
      "1649/1649 [==============================] - 1s 309us/step - loss: 0.6875 - acc: 0.8411 - val_loss: 0.7336 - val_acc: 0.8184\n",
      "Epoch 161/1000\n",
      "1649/1649 [==============================] - 0s 245us/step - loss: 0.6859 - acc: 0.8448 - val_loss: 0.7302 - val_acc: 0.8184\n",
      "Epoch 162/1000\n",
      "1649/1649 [==============================] - 0s 267us/step - loss: 0.6834 - acc: 0.8399 - val_loss: 0.7311 - val_acc: 0.8208\n",
      "Epoch 163/1000\n",
      "1649/1649 [==============================] - 0s 295us/step - loss: 0.6824 - acc: 0.8423 - val_loss: 0.7233 - val_acc: 0.8111\n",
      "Epoch 164/1000\n",
      "1649/1649 [==============================] - 0s 206us/step - loss: 0.6801 - acc: 0.8448 - val_loss: 0.7239 - val_acc: 0.8208\n",
      "Epoch 165/1000\n",
      "1649/1649 [==============================] - 0s 232us/step - loss: 0.6787 - acc: 0.8435 - val_loss: 0.7230 - val_acc: 0.8257\n",
      "Epoch 166/1000\n",
      "1649/1649 [==============================] - 0s 227us/step - loss: 0.6770 - acc: 0.8490 - val_loss: 0.7192 - val_acc: 0.8160\n",
      "Epoch 167/1000\n",
      "1649/1649 [==============================] - 0s 227us/step - loss: 0.6743 - acc: 0.8472 - val_loss: 0.7211 - val_acc: 0.8160\n",
      "Epoch 168/1000\n",
      "1649/1649 [==============================] - 0s 236us/step - loss: 0.6737 - acc: 0.8417 - val_loss: 0.7185 - val_acc: 0.8208\n",
      "Epoch 169/1000\n",
      "1649/1649 [==============================] - 0s 202us/step - loss: 0.6714 - acc: 0.8466 - val_loss: 0.7165 - val_acc: 0.8232\n",
      "Epoch 170/1000\n",
      "1649/1649 [==============================] - 0s 221us/step - loss: 0.6702 - acc: 0.8460 - val_loss: 0.7141 - val_acc: 0.8184\n",
      "Epoch 171/1000\n",
      "1649/1649 [==============================] - 0s 209us/step - loss: 0.6683 - acc: 0.8484 - val_loss: 0.7137 - val_acc: 0.8160\n",
      "Epoch 172/1000\n",
      "1649/1649 [==============================] - 0s 197us/step - loss: 0.6678 - acc: 0.8484 - val_loss: 0.7081 - val_acc: 0.8281\n",
      "Epoch 173/1000\n",
      "1649/1649 [==============================] - 0s 214us/step - loss: 0.6645 - acc: 0.8490 - val_loss: 0.7094 - val_acc: 0.8208\n",
      "Epoch 174/1000\n",
      "1649/1649 [==============================] - 0s 229us/step - loss: 0.6629 - acc: 0.8466 - val_loss: 0.7080 - val_acc: 0.8184\n",
      "Epoch 175/1000\n",
      "1649/1649 [==============================] - 0s 209us/step - loss: 0.6609 - acc: 0.8496 - val_loss: 0.7059 - val_acc: 0.8257\n",
      "Epoch 176/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1649/1649 [==============================] - 0s 206us/step - loss: 0.6601 - acc: 0.8514 - val_loss: 0.7036 - val_acc: 0.8208\n",
      "Epoch 177/1000\n",
      "1649/1649 [==============================] - 0s 181us/step - loss: 0.6584 - acc: 0.8532 - val_loss: 0.7036 - val_acc: 0.8208\n",
      "Epoch 178/1000\n",
      "1649/1649 [==============================] - 0s 172us/step - loss: 0.6572 - acc: 0.8472 - val_loss: 0.7051 - val_acc: 0.8208\n",
      "Epoch 179/1000\n",
      "1649/1649 [==============================] - 0s 173us/step - loss: 0.6549 - acc: 0.8484 - val_loss: 0.7008 - val_acc: 0.8232\n",
      "Epoch 180/1000\n",
      "1649/1649 [==============================] - 0s 188us/step - loss: 0.6540 - acc: 0.8526 - val_loss: 0.7033 - val_acc: 0.8281\n",
      "Epoch 181/1000\n",
      "1649/1649 [==============================] - 0s 177us/step - loss: 0.6523 - acc: 0.8472 - val_loss: 0.6992 - val_acc: 0.8232\n",
      "Epoch 182/1000\n",
      "1649/1649 [==============================] - 0s 174us/step - loss: 0.6507 - acc: 0.8563 - val_loss: 0.6965 - val_acc: 0.8184\n",
      "Epoch 183/1000\n",
      "1649/1649 [==============================] - 0s 189us/step - loss: 0.6488 - acc: 0.8490 - val_loss: 0.6936 - val_acc: 0.8257\n",
      "Epoch 184/1000\n",
      "1649/1649 [==============================] - 0s 168us/step - loss: 0.6469 - acc: 0.8551 - val_loss: 0.6920 - val_acc: 0.8232\n",
      "Epoch 185/1000\n",
      "1649/1649 [==============================] - 0s 169us/step - loss: 0.6462 - acc: 0.8514 - val_loss: 0.6882 - val_acc: 0.8257\n",
      "Epoch 186/1000\n",
      "1649/1649 [==============================] - 0s 175us/step - loss: 0.6441 - acc: 0.8545 - val_loss: 0.6882 - val_acc: 0.8257\n",
      "Epoch 187/1000\n",
      "1649/1649 [==============================] - 0s 189us/step - loss: 0.6426 - acc: 0.8545 - val_loss: 0.6891 - val_acc: 0.8257\n",
      "Epoch 188/1000\n",
      "1649/1649 [==============================] - 0s 186us/step - loss: 0.6410 - acc: 0.8520 - val_loss: 0.6885 - val_acc: 0.8232\n",
      "Epoch 189/1000\n",
      "1649/1649 [==============================] - 0s 186us/step - loss: 0.6396 - acc: 0.8563 - val_loss: 0.6842 - val_acc: 0.8257\n",
      "Epoch 190/1000\n",
      "1649/1649 [==============================] - 0s 184us/step - loss: 0.6378 - acc: 0.8551 - val_loss: 0.6853 - val_acc: 0.8208\n",
      "Epoch 191/1000\n",
      "1649/1649 [==============================] - 0s 184us/step - loss: 0.6369 - acc: 0.8508 - val_loss: 0.6840 - val_acc: 0.8257\n",
      "Epoch 192/1000\n",
      "1649/1649 [==============================] - 0s 182us/step - loss: 0.6355 - acc: 0.8526 - val_loss: 0.6799 - val_acc: 0.8281\n",
      "Epoch 193/1000\n",
      "1649/1649 [==============================] - 0s 189us/step - loss: 0.6345 - acc: 0.8551 - val_loss: 0.6813 - val_acc: 0.8232\n",
      "Epoch 194/1000\n",
      "1649/1649 [==============================] - 0s 187us/step - loss: 0.6325 - acc: 0.8545 - val_loss: 0.6800 - val_acc: 0.8257\n",
      "Epoch 195/1000\n",
      "1649/1649 [==============================] - 0s 170us/step - loss: 0.6307 - acc: 0.8575 - val_loss: 0.6762 - val_acc: 0.8305\n",
      "Epoch 196/1000\n",
      "1649/1649 [==============================] - 0s 229us/step - loss: 0.6296 - acc: 0.8569 - val_loss: 0.6748 - val_acc: 0.8208\n",
      "Epoch 197/1000\n",
      "1649/1649 [==============================] - 0s 206us/step - loss: 0.6291 - acc: 0.8532 - val_loss: 0.6710 - val_acc: 0.8257\n",
      "Epoch 198/1000\n",
      "1649/1649 [==============================] - 0s 201us/step - loss: 0.6274 - acc: 0.8605 - val_loss: 0.6735 - val_acc: 0.8232\n",
      "Epoch 199/1000\n",
      "1649/1649 [==============================] - 0s 235us/step - loss: 0.6256 - acc: 0.8575 - val_loss: 0.6697 - val_acc: 0.8257\n",
      "Epoch 200/1000\n",
      "1649/1649 [==============================] - 0s 233us/step - loss: 0.6238 - acc: 0.8599 - val_loss: 0.6695 - val_acc: 0.8281\n",
      "Epoch 201/1000\n",
      "1649/1649 [==============================] - 0s 213us/step - loss: 0.6226 - acc: 0.8587 - val_loss: 0.6694 - val_acc: 0.8257\n",
      "Epoch 202/1000\n",
      "1649/1649 [==============================] - 0s 226us/step - loss: 0.6208 - acc: 0.8605 - val_loss: 0.6680 - val_acc: 0.8208\n",
      "Epoch 203/1000\n",
      "1649/1649 [==============================] - 0s 208us/step - loss: 0.6199 - acc: 0.8575 - val_loss: 0.6656 - val_acc: 0.8257\n",
      "Epoch 204/1000\n",
      "1649/1649 [==============================] - 0s 279us/step - loss: 0.6182 - acc: 0.8587 - val_loss: 0.6630 - val_acc: 0.8281\n",
      "Epoch 205/1000\n",
      "1649/1649 [==============================] - 0s 283us/step - loss: 0.6175 - acc: 0.8611 - val_loss: 0.6619 - val_acc: 0.8305\n",
      "Epoch 206/1000\n",
      "1649/1649 [==============================] - 0s 261us/step - loss: 0.6167 - acc: 0.8581 - val_loss: 0.6625 - val_acc: 0.8257\n",
      "Epoch 207/1000\n",
      "1649/1649 [==============================] - 0s 232us/step - loss: 0.6145 - acc: 0.8593 - val_loss: 0.6595 - val_acc: 0.8305\n",
      "Epoch 208/1000\n",
      "1649/1649 [==============================] - 1s 314us/step - loss: 0.6137 - acc: 0.8599 - val_loss: 0.6584 - val_acc: 0.8281\n",
      "Epoch 209/1000\n",
      "1649/1649 [==============================] - 0s 270us/step - loss: 0.6132 - acc: 0.8629 - val_loss: 0.6591 - val_acc: 0.8305\n",
      "Epoch 210/1000\n",
      "1649/1649 [==============================] - 0s 232us/step - loss: 0.6108 - acc: 0.8605 - val_loss: 0.6570 - val_acc: 0.8305\n",
      "Epoch 211/1000\n",
      "1649/1649 [==============================] - 0s 228us/step - loss: 0.6097 - acc: 0.8623 - val_loss: 0.6572 - val_acc: 0.8257\n",
      "Epoch 212/1000\n",
      "1649/1649 [==============================] - 0s 207us/step - loss: 0.6084 - acc: 0.8617 - val_loss: 0.6524 - val_acc: 0.8305\n",
      "Epoch 213/1000\n",
      "1649/1649 [==============================] - 0s 220us/step - loss: 0.6072 - acc: 0.8636 - val_loss: 0.6538 - val_acc: 0.8281\n",
      "Epoch 214/1000\n",
      "1649/1649 [==============================] - 0s 235us/step - loss: 0.6057 - acc: 0.8623 - val_loss: 0.6524 - val_acc: 0.8329\n",
      "Epoch 215/1000\n",
      "1649/1649 [==============================] - 0s 213us/step - loss: 0.6044 - acc: 0.8605 - val_loss: 0.6491 - val_acc: 0.8305\n",
      "Epoch 216/1000\n",
      "1649/1649 [==============================] - 0s 212us/step - loss: 0.6035 - acc: 0.8617 - val_loss: 0.6520 - val_acc: 0.8257\n",
      "Epoch 217/1000\n",
      "1649/1649 [==============================] - 0s 208us/step - loss: 0.6025 - acc: 0.8611 - val_loss: 0.6489 - val_acc: 0.8329\n",
      "Epoch 218/1000\n",
      "1649/1649 [==============================] - 0s 202us/step - loss: 0.6010 - acc: 0.8642 - val_loss: 0.6472 - val_acc: 0.8281\n",
      "Epoch 219/1000\n",
      "1649/1649 [==============================] - 0s 210us/step - loss: 0.5994 - acc: 0.8642 - val_loss: 0.6460 - val_acc: 0.8281\n",
      "Epoch 220/1000\n",
      "1649/1649 [==============================] - 0s 204us/step - loss: 0.5983 - acc: 0.8623 - val_loss: 0.6460 - val_acc: 0.8329\n",
      "Epoch 221/1000\n",
      "1649/1649 [==============================] - 0s 225us/step - loss: 0.5975 - acc: 0.8617 - val_loss: 0.6442 - val_acc: 0.8329\n",
      "Epoch 222/1000\n",
      "1649/1649 [==============================] - 0s 215us/step - loss: 0.5965 - acc: 0.8617 - val_loss: 0.6433 - val_acc: 0.8329\n",
      "Epoch 223/1000\n",
      "1649/1649 [==============================] - 0s 219us/step - loss: 0.5949 - acc: 0.8636 - val_loss: 0.6420 - val_acc: 0.8329\n",
      "Epoch 224/1000\n",
      "1649/1649 [==============================] - 0s 210us/step - loss: 0.5950 - acc: 0.8642 - val_loss: 0.6406 - val_acc: 0.8329\n",
      "Epoch 225/1000\n",
      "1649/1649 [==============================] - 0s 203us/step - loss: 0.5927 - acc: 0.8654 - val_loss: 0.6408 - val_acc: 0.8378\n",
      "Epoch 226/1000\n",
      "1649/1649 [==============================] - 0s 221us/step - loss: 0.5917 - acc: 0.8636 - val_loss: 0.6386 - val_acc: 0.8305\n",
      "Epoch 227/1000\n",
      "1649/1649 [==============================] - 0s 224us/step - loss: 0.5910 - acc: 0.8629 - val_loss: 0.6378 - val_acc: 0.8354\n",
      "Epoch 228/1000\n",
      "1649/1649 [==============================] - 0s 227us/step - loss: 0.5899 - acc: 0.8672 - val_loss: 0.6367 - val_acc: 0.8378\n",
      "Epoch 229/1000\n",
      "1649/1649 [==============================] - 0s 233us/step - loss: 0.5883 - acc: 0.8666 - val_loss: 0.6347 - val_acc: 0.8329\n",
      "Epoch 230/1000\n",
      "1649/1649 [==============================] - 0s 223us/step - loss: 0.5872 - acc: 0.8617 - val_loss: 0.6324 - val_acc: 0.8354\n",
      "Epoch 231/1000\n",
      "1649/1649 [==============================] - 0s 226us/step - loss: 0.5858 - acc: 0.8660 - val_loss: 0.6353 - val_acc: 0.8329\n",
      "Epoch 232/1000\n",
      "1649/1649 [==============================] - 0s 235us/step - loss: 0.5848 - acc: 0.8678 - val_loss: 0.6309 - val_acc: 0.8305\n",
      "Epoch 233/1000\n",
      "1649/1649 [==============================] - 0s 202us/step - loss: 0.5840 - acc: 0.8654 - val_loss: 0.6303 - val_acc: 0.8354\n",
      "Epoch 234/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1649/1649 [==============================] - 0s 185us/step - loss: 0.5822 - acc: 0.8642 - val_loss: 0.6289 - val_acc: 0.8354\n",
      "Epoch 235/1000\n",
      "1649/1649 [==============================] - 0s 194us/step - loss: 0.5818 - acc: 0.8642 - val_loss: 0.6280 - val_acc: 0.8354\n",
      "Epoch 236/1000\n",
      "1649/1649 [==============================] - 0s 194us/step - loss: 0.5803 - acc: 0.8672 - val_loss: 0.6256 - val_acc: 0.8378\n",
      "Epoch 237/1000\n",
      "1649/1649 [==============================] - 0s 190us/step - loss: 0.5795 - acc: 0.8660 - val_loss: 0.6280 - val_acc: 0.8354\n",
      "Epoch 238/1000\n",
      "1649/1649 [==============================] - 0s 194us/step - loss: 0.5785 - acc: 0.8654 - val_loss: 0.6265 - val_acc: 0.8426\n",
      "Epoch 239/1000\n",
      "1649/1649 [==============================] - 0s 190us/step - loss: 0.5777 - acc: 0.8666 - val_loss: 0.6227 - val_acc: 0.8402\n",
      "Epoch 240/1000\n",
      "1649/1649 [==============================] - 0s 188us/step - loss: 0.5766 - acc: 0.8702 - val_loss: 0.6235 - val_acc: 0.8305\n",
      "Epoch 241/1000\n",
      "1649/1649 [==============================] - 0s 184us/step - loss: 0.5753 - acc: 0.8672 - val_loss: 0.6237 - val_acc: 0.8402\n",
      "Epoch 242/1000\n",
      "1649/1649 [==============================] - 0s 191us/step - loss: 0.5741 - acc: 0.8702 - val_loss: 0.6212 - val_acc: 0.8329\n",
      "Epoch 243/1000\n",
      "1649/1649 [==============================] - 0s 180us/step - loss: 0.5731 - acc: 0.8696 - val_loss: 0.6223 - val_acc: 0.8329\n",
      "Epoch 244/1000\n",
      "1649/1649 [==============================] - 0s 181us/step - loss: 0.5722 - acc: 0.8660 - val_loss: 0.6195 - val_acc: 0.8378\n",
      "Epoch 245/1000\n",
      "1649/1649 [==============================] - 0s 198us/step - loss: 0.5720 - acc: 0.8708 - val_loss: 0.6206 - val_acc: 0.8305\n",
      "Epoch 246/1000\n",
      "1649/1649 [==============================] - 0s 187us/step - loss: 0.5701 - acc: 0.8684 - val_loss: 0.6172 - val_acc: 0.8354\n",
      "Epoch 247/1000\n",
      "1649/1649 [==============================] - 0s 180us/step - loss: 0.5693 - acc: 0.8672 - val_loss: 0.6152 - val_acc: 0.8378\n",
      "Epoch 248/1000\n",
      "1649/1649 [==============================] - 0s 218us/step - loss: 0.5681 - acc: 0.8702 - val_loss: 0.6150 - val_acc: 0.8450\n",
      "Epoch 249/1000\n",
      "1649/1649 [==============================] - 0s 277us/step - loss: 0.5675 - acc: 0.8690 - val_loss: 0.6130 - val_acc: 0.8354\n",
      "Epoch 250/1000\n",
      "1649/1649 [==============================] - 1s 330us/step - loss: 0.5668 - acc: 0.8660 - val_loss: 0.6140 - val_acc: 0.8402\n",
      "Epoch 251/1000\n",
      "1649/1649 [==============================] - 0s 274us/step - loss: 0.5651 - acc: 0.8708 - val_loss: 0.6126 - val_acc: 0.8402\n",
      "Epoch 252/1000\n",
      "1649/1649 [==============================] - 0s 203us/step - loss: 0.5640 - acc: 0.8702 - val_loss: 0.6110 - val_acc: 0.8426\n",
      "Epoch 253/1000\n",
      "1649/1649 [==============================] - 0s 290us/step - loss: 0.5630 - acc: 0.8745 - val_loss: 0.6112 - val_acc: 0.8329\n",
      "Epoch 254/1000\n",
      "1649/1649 [==============================] - 0s 217us/step - loss: 0.5620 - acc: 0.8678 - val_loss: 0.6084 - val_acc: 0.8475\n",
      "Epoch 255/1000\n",
      "1649/1649 [==============================] - 0s 258us/step - loss: 0.5614 - acc: 0.8690 - val_loss: 0.6094 - val_acc: 0.8354\n",
      "Epoch 256/1000\n",
      "1649/1649 [==============================] - 0s 210us/step - loss: 0.5602 - acc: 0.8720 - val_loss: 0.6091 - val_acc: 0.8426\n",
      "Epoch 257/1000\n",
      "1649/1649 [==============================] - 0s 227us/step - loss: 0.5589 - acc: 0.8727 - val_loss: 0.6073 - val_acc: 0.8402\n",
      "Epoch 258/1000\n",
      "1649/1649 [==============================] - 0s 236us/step - loss: 0.5585 - acc: 0.8696 - val_loss: 0.6054 - val_acc: 0.8378\n",
      "Epoch 259/1000\n",
      "1649/1649 [==============================] - 0s 212us/step - loss: 0.5573 - acc: 0.8720 - val_loss: 0.6040 - val_acc: 0.8402\n",
      "Epoch 260/1000\n",
      "1649/1649 [==============================] - 0s 205us/step - loss: 0.5574 - acc: 0.8733 - val_loss: 0.6039 - val_acc: 0.8354\n",
      "Epoch 261/1000\n",
      "1649/1649 [==============================] - 0s 229us/step - loss: 0.5554 - acc: 0.8733 - val_loss: 0.6047 - val_acc: 0.8426\n",
      "Epoch 262/1000\n",
      "1649/1649 [==============================] - 0s 204us/step - loss: 0.5546 - acc: 0.8727 - val_loss: 0.6023 - val_acc: 0.8426\n",
      "Epoch 263/1000\n",
      "1649/1649 [==============================] - 0s 211us/step - loss: 0.5536 - acc: 0.8733 - val_loss: 0.6030 - val_acc: 0.8329\n",
      "Epoch 264/1000\n",
      "1649/1649 [==============================] - 0s 227us/step - loss: 0.5525 - acc: 0.8702 - val_loss: 0.5981 - val_acc: 0.8547\n",
      "Epoch 265/1000\n",
      "1649/1649 [==============================] - 0s 198us/step - loss: 0.5518 - acc: 0.8708 - val_loss: 0.5983 - val_acc: 0.8426\n",
      "Epoch 266/1000\n",
      "1649/1649 [==============================] - 0s 203us/step - loss: 0.5507 - acc: 0.8751 - val_loss: 0.5989 - val_acc: 0.8475\n",
      "Epoch 267/1000\n",
      "1649/1649 [==============================] - 0s 248us/step - loss: 0.5497 - acc: 0.8757 - val_loss: 0.6000 - val_acc: 0.8450\n",
      "Epoch 268/1000\n",
      "1649/1649 [==============================] - 0s 242us/step - loss: 0.5495 - acc: 0.8708 - val_loss: 0.5951 - val_acc: 0.8475\n",
      "Epoch 269/1000\n",
      "1649/1649 [==============================] - 0s 231us/step - loss: 0.5488 - acc: 0.8727 - val_loss: 0.5967 - val_acc: 0.8426\n",
      "Epoch 270/1000\n",
      "1649/1649 [==============================] - 0s 236us/step - loss: 0.5471 - acc: 0.8739 - val_loss: 0.5947 - val_acc: 0.8378\n",
      "Epoch 271/1000\n",
      "1649/1649 [==============================] - 0s 232us/step - loss: 0.5464 - acc: 0.8714 - val_loss: 0.5939 - val_acc: 0.8426\n",
      "Epoch 272/1000\n",
      "1649/1649 [==============================] - 0s 232us/step - loss: 0.5458 - acc: 0.8751 - val_loss: 0.5911 - val_acc: 0.8571\n",
      "Epoch 273/1000\n",
      "1649/1649 [==============================] - 0s 213us/step - loss: 0.5442 - acc: 0.8769 - val_loss: 0.5939 - val_acc: 0.8378\n",
      "Epoch 274/1000\n",
      "1649/1649 [==============================] - 0s 233us/step - loss: 0.5437 - acc: 0.8745 - val_loss: 0.5909 - val_acc: 0.8426\n",
      "Epoch 275/1000\n",
      "1649/1649 [==============================] - 0s 239us/step - loss: 0.5431 - acc: 0.8727 - val_loss: 0.5922 - val_acc: 0.8475\n",
      "Epoch 276/1000\n",
      "1649/1649 [==============================] - 0s 212us/step - loss: 0.5420 - acc: 0.8745 - val_loss: 0.5883 - val_acc: 0.8499\n",
      "Epoch 277/1000\n",
      "1649/1649 [==============================] - 0s 234us/step - loss: 0.5407 - acc: 0.8769 - val_loss: 0.5901 - val_acc: 0.8450\n",
      "Epoch 278/1000\n",
      "1649/1649 [==============================] - 0s 219us/step - loss: 0.5397 - acc: 0.8727 - val_loss: 0.5870 - val_acc: 0.8475\n",
      "Epoch 279/1000\n",
      "1649/1649 [==============================] - 0s 226us/step - loss: 0.5394 - acc: 0.8781 - val_loss: 0.5874 - val_acc: 0.8475\n",
      "Epoch 280/1000\n",
      "1649/1649 [==============================] - 0s 261us/step - loss: 0.5384 - acc: 0.8781 - val_loss: 0.5861 - val_acc: 0.8499\n",
      "Epoch 281/1000\n",
      "1649/1649 [==============================] - 0s 228us/step - loss: 0.5376 - acc: 0.8763 - val_loss: 0.5843 - val_acc: 0.8450\n",
      "Epoch 282/1000\n",
      "1649/1649 [==============================] - 0s 238us/step - loss: 0.5367 - acc: 0.8793 - val_loss: 0.5861 - val_acc: 0.8402\n",
      "Epoch 283/1000\n",
      "1649/1649 [==============================] - 0s 218us/step - loss: 0.5362 - acc: 0.8733 - val_loss: 0.5827 - val_acc: 0.8596\n",
      "Epoch 284/1000\n",
      "1649/1649 [==============================] - 0s 220us/step - loss: 0.5355 - acc: 0.8787 - val_loss: 0.5810 - val_acc: 0.8596\n",
      "Epoch 285/1000\n",
      "1649/1649 [==============================] - 0s 234us/step - loss: 0.5343 - acc: 0.8763 - val_loss: 0.5811 - val_acc: 0.8547\n",
      "Epoch 286/1000\n",
      "1649/1649 [==============================] - 0s 233us/step - loss: 0.5333 - acc: 0.8805 - val_loss: 0.5822 - val_acc: 0.8475\n",
      "Epoch 287/1000\n",
      "1649/1649 [==============================] - 0s 244us/step - loss: 0.5326 - acc: 0.8757 - val_loss: 0.5821 - val_acc: 0.8475\n",
      "Epoch 288/1000\n",
      "1649/1649 [==============================] - 0s 249us/step - loss: 0.5315 - acc: 0.8769 - val_loss: 0.5773 - val_acc: 0.8571\n",
      "Epoch 289/1000\n",
      "1649/1649 [==============================] - 0s 196us/step - loss: 0.5307 - acc: 0.8817 - val_loss: 0.5801 - val_acc: 0.8475\n",
      "Epoch 290/1000\n",
      "1649/1649 [==============================] - 1s 340us/step - loss: 0.5304 - acc: 0.8787 - val_loss: 0.5789 - val_acc: 0.8475\n",
      "Epoch 291/1000\n",
      "1649/1649 [==============================] - 0s 286us/step - loss: 0.5295 - acc: 0.8787 - val_loss: 0.5789 - val_acc: 0.8475\n",
      "Epoch 292/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1649/1649 [==============================] - 0s 285us/step - loss: 0.5284 - acc: 0.8763 - val_loss: 0.5759 - val_acc: 0.8571\n",
      "Epoch 293/1000\n",
      "1649/1649 [==============================] - 0s 215us/step - loss: 0.5273 - acc: 0.8787 - val_loss: 0.5744 - val_acc: 0.8596\n",
      "Epoch 294/1000\n",
      "1649/1649 [==============================] - 0s 257us/step - loss: 0.5269 - acc: 0.8805 - val_loss: 0.5742 - val_acc: 0.8596\n",
      "Epoch 295/1000\n",
      "1649/1649 [==============================] - 0s 208us/step - loss: 0.5261 - acc: 0.8793 - val_loss: 0.5750 - val_acc: 0.8523\n",
      "Epoch 296/1000\n",
      "1649/1649 [==============================] - 0s 186us/step - loss: 0.5250 - acc: 0.8775 - val_loss: 0.5747 - val_acc: 0.8475\n",
      "Epoch 297/1000\n",
      "1649/1649 [==============================] - 0s 183us/step - loss: 0.5248 - acc: 0.8775 - val_loss: 0.5717 - val_acc: 0.8571\n",
      "Epoch 298/1000\n",
      "1649/1649 [==============================] - 0s 192us/step - loss: 0.5243 - acc: 0.8745 - val_loss: 0.5694 - val_acc: 0.8620\n",
      "Epoch 299/1000\n",
      "1649/1649 [==============================] - 0s 174us/step - loss: 0.5226 - acc: 0.8781 - val_loss: 0.5719 - val_acc: 0.8523\n",
      "Epoch 300/1000\n",
      "1649/1649 [==============================] - 0s 173us/step - loss: 0.5223 - acc: 0.8799 - val_loss: 0.5693 - val_acc: 0.8596\n",
      "Epoch 301/1000\n",
      "1649/1649 [==============================] - 0s 187us/step - loss: 0.5215 - acc: 0.8799 - val_loss: 0.5698 - val_acc: 0.8596\n",
      "Epoch 302/1000\n",
      "1649/1649 [==============================] - 0s 188us/step - loss: 0.5206 - acc: 0.8769 - val_loss: 0.5690 - val_acc: 0.8547\n",
      "Epoch 303/1000\n",
      "1649/1649 [==============================] - 0s 170us/step - loss: 0.5197 - acc: 0.8763 - val_loss: 0.5672 - val_acc: 0.8644\n",
      "Epoch 304/1000\n",
      "1649/1649 [==============================] - 0s 175us/step - loss: 0.5196 - acc: 0.8757 - val_loss: 0.5674 - val_acc: 0.8571\n",
      "Epoch 305/1000\n",
      "1649/1649 [==============================] - 0s 192us/step - loss: 0.5185 - acc: 0.8799 - val_loss: 0.5669 - val_acc: 0.8547\n",
      "Epoch 306/1000\n",
      "1649/1649 [==============================] - 0s 178us/step - loss: 0.5181 - acc: 0.8775 - val_loss: 0.5685 - val_acc: 0.8523\n",
      "Epoch 307/1000\n",
      "1649/1649 [==============================] - 0s 176us/step - loss: 0.5172 - acc: 0.8769 - val_loss: 0.5670 - val_acc: 0.8571\n",
      "Epoch 308/1000\n",
      "1649/1649 [==============================] - 0s 175us/step - loss: 0.5173 - acc: 0.8830 - val_loss: 0.5651 - val_acc: 0.8571\n",
      "Epoch 309/1000\n",
      "1649/1649 [==============================] - 0s 180us/step - loss: 0.5155 - acc: 0.8811 - val_loss: 0.5641 - val_acc: 0.8571\n",
      "Epoch 310/1000\n",
      "1649/1649 [==============================] - 0s 185us/step - loss: 0.5152 - acc: 0.8781 - val_loss: 0.5619 - val_acc: 0.8644\n",
      "Epoch 311/1000\n",
      "1649/1649 [==============================] - 0s 175us/step - loss: 0.5142 - acc: 0.8836 - val_loss: 0.5618 - val_acc: 0.8620\n",
      "Epoch 312/1000\n",
      "1649/1649 [==============================] - 0s 189us/step - loss: 0.5135 - acc: 0.8799 - val_loss: 0.5635 - val_acc: 0.8499\n",
      "Epoch 313/1000\n",
      "1649/1649 [==============================] - 0s 172us/step - loss: 0.5129 - acc: 0.8805 - val_loss: 0.5610 - val_acc: 0.8547\n",
      "Epoch 314/1000\n",
      "1649/1649 [==============================] - 0s 176us/step - loss: 0.5120 - acc: 0.8854 - val_loss: 0.5611 - val_acc: 0.8571\n",
      "Epoch 315/1000\n",
      "1649/1649 [==============================] - 0s 190us/step - loss: 0.5112 - acc: 0.8836 - val_loss: 0.5594 - val_acc: 0.8620\n",
      "Epoch 316/1000\n",
      "1649/1649 [==============================] - 0s 192us/step - loss: 0.5106 - acc: 0.8824 - val_loss: 0.5582 - val_acc: 0.8620\n",
      "Epoch 317/1000\n",
      "1649/1649 [==============================] - 0s 192us/step - loss: 0.5096 - acc: 0.8836 - val_loss: 0.5574 - val_acc: 0.8668\n",
      "Epoch 318/1000\n",
      "1649/1649 [==============================] - 0s 173us/step - loss: 0.5092 - acc: 0.8854 - val_loss: 0.5571 - val_acc: 0.8596\n",
      "Epoch 319/1000\n",
      "1649/1649 [==============================] - 0s 189us/step - loss: 0.5079 - acc: 0.8805 - val_loss: 0.5585 - val_acc: 0.8571\n",
      "Epoch 320/1000\n",
      "1649/1649 [==============================] - 0s 199us/step - loss: 0.5078 - acc: 0.8811 - val_loss: 0.5561 - val_acc: 0.8620\n",
      "Epoch 321/1000\n",
      "1649/1649 [==============================] - 0s 192us/step - loss: 0.5070 - acc: 0.8824 - val_loss: 0.5535 - val_acc: 0.8644\n",
      "Epoch 322/1000\n",
      "1649/1649 [==============================] - 0s 188us/step - loss: 0.5060 - acc: 0.8830 - val_loss: 0.5560 - val_acc: 0.8596\n",
      "Epoch 323/1000\n",
      "1649/1649 [==============================] - 0s 185us/step - loss: 0.5053 - acc: 0.8799 - val_loss: 0.5536 - val_acc: 0.8620\n",
      "Epoch 324/1000\n",
      "1649/1649 [==============================] - 0s 189us/step - loss: 0.5047 - acc: 0.8787 - val_loss: 0.5532 - val_acc: 0.8620\n",
      "Epoch 325/1000\n",
      "1649/1649 [==============================] - 0s 200us/step - loss: 0.5042 - acc: 0.8854 - val_loss: 0.5528 - val_acc: 0.8596\n",
      "Epoch 326/1000\n",
      "1649/1649 [==============================] - 0s 190us/step - loss: 0.5037 - acc: 0.8811 - val_loss: 0.5509 - val_acc: 0.8668\n",
      "Epoch 327/1000\n",
      "1649/1649 [==============================] - 0s 197us/step - loss: 0.5026 - acc: 0.8817 - val_loss: 0.5530 - val_acc: 0.8571\n",
      "Epoch 328/1000\n",
      "1649/1649 [==============================] - 0s 189us/step - loss: 0.5025 - acc: 0.8811 - val_loss: 0.5505 - val_acc: 0.8644\n",
      "Epoch 329/1000\n",
      "1649/1649 [==============================] - 0s 192us/step - loss: 0.5014 - acc: 0.8842 - val_loss: 0.5507 - val_acc: 0.8620\n",
      "Epoch 330/1000\n",
      "1649/1649 [==============================] - 0s 192us/step - loss: 0.5004 - acc: 0.8824 - val_loss: 0.5493 - val_acc: 0.8668\n",
      "Epoch 331/1000\n",
      "1649/1649 [==============================] - 0s 182us/step - loss: 0.5001 - acc: 0.8836 - val_loss: 0.5478 - val_acc: 0.8692\n",
      "Epoch 332/1000\n",
      "1649/1649 [==============================] - 0s 192us/step - loss: 0.4991 - acc: 0.8817 - val_loss: 0.5496 - val_acc: 0.8644\n",
      "Epoch 333/1000\n",
      "1649/1649 [==============================] - 0s 190us/step - loss: 0.4989 - acc: 0.8872 - val_loss: 0.5486 - val_acc: 0.8620\n",
      "Epoch 334/1000\n",
      "1649/1649 [==============================] - 0s 190us/step - loss: 0.4979 - acc: 0.8830 - val_loss: 0.5467 - val_acc: 0.8644\n",
      "Epoch 335/1000\n",
      "1649/1649 [==============================] - 0s 206us/step - loss: 0.4975 - acc: 0.8811 - val_loss: 0.5467 - val_acc: 0.8668\n",
      "Epoch 336/1000\n",
      "1649/1649 [==============================] - 0s 184us/step - loss: 0.4971 - acc: 0.8842 - val_loss: 0.5443 - val_acc: 0.8668\n",
      "Epoch 337/1000\n",
      "1649/1649 [==============================] - 0s 187us/step - loss: 0.4962 - acc: 0.8872 - val_loss: 0.5456 - val_acc: 0.8620\n",
      "Epoch 338/1000\n",
      "1649/1649 [==============================] - 0s 196us/step - loss: 0.4958 - acc: 0.8854 - val_loss: 0.5450 - val_acc: 0.8620\n",
      "Epoch 339/1000\n",
      "1649/1649 [==============================] - 0s 215us/step - loss: 0.4948 - acc: 0.8842 - val_loss: 0.5431 - val_acc: 0.8717\n",
      "Epoch 340/1000\n",
      "1649/1649 [==============================] - 0s 243us/step - loss: 0.4939 - acc: 0.8848 - val_loss: 0.5448 - val_acc: 0.8644\n",
      "Epoch 341/1000\n",
      "1649/1649 [==============================] - 0s 266us/step - loss: 0.4933 - acc: 0.8836 - val_loss: 0.5427 - val_acc: 0.8620\n",
      "Epoch 342/1000\n",
      "1649/1649 [==============================] - 0s 249us/step - loss: 0.4927 - acc: 0.8872 - val_loss: 0.5412 - val_acc: 0.8692\n",
      "Epoch 343/1000\n",
      "1649/1649 [==============================] - 0s 233us/step - loss: 0.4924 - acc: 0.8848 - val_loss: 0.5417 - val_acc: 0.8668\n",
      "Epoch 344/1000\n",
      "1649/1649 [==============================] - 0s 270us/step - loss: 0.4924 - acc: 0.8817 - val_loss: 0.5382 - val_acc: 0.8717\n",
      "Epoch 345/1000\n",
      "1649/1649 [==============================] - 0s 192us/step - loss: 0.4909 - acc: 0.8872 - val_loss: 0.5415 - val_acc: 0.8620\n",
      "Epoch 346/1000\n",
      "1649/1649 [==============================] - 0s 203us/step - loss: 0.4902 - acc: 0.8854 - val_loss: 0.5411 - val_acc: 0.8620\n",
      "Epoch 347/1000\n",
      "1649/1649 [==============================] - 0s 198us/step - loss: 0.4897 - acc: 0.8836 - val_loss: 0.5393 - val_acc: 0.8692\n",
      "Epoch 348/1000\n",
      "1649/1649 [==============================] - 0s 184us/step - loss: 0.4891 - acc: 0.8824 - val_loss: 0.5378 - val_acc: 0.8717\n",
      "Epoch 349/1000\n",
      "1649/1649 [==============================] - 0s 192us/step - loss: 0.4884 - acc: 0.8848 - val_loss: 0.5364 - val_acc: 0.8692\n",
      "Epoch 350/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1649/1649 [==============================] - 0s 198us/step - loss: 0.4878 - acc: 0.8866 - val_loss: 0.5362 - val_acc: 0.8717\n",
      "Epoch 351/1000\n",
      "1649/1649 [==============================] - 0s 193us/step - loss: 0.4871 - acc: 0.8860 - val_loss: 0.5361 - val_acc: 0.8741\n",
      "Epoch 352/1000\n",
      "1649/1649 [==============================] - 0s 176us/step - loss: 0.4867 - acc: 0.8811 - val_loss: 0.5353 - val_acc: 0.8717\n",
      "Epoch 353/1000\n",
      "1649/1649 [==============================] - 0s 182us/step - loss: 0.4862 - acc: 0.8896 - val_loss: 0.5356 - val_acc: 0.8620\n",
      "Epoch 354/1000\n",
      "1649/1649 [==============================] - 0s 186us/step - loss: 0.4853 - acc: 0.8860 - val_loss: 0.5347 - val_acc: 0.8741\n",
      "Epoch 355/1000\n",
      "1649/1649 [==============================] - 0s 212us/step - loss: 0.4856 - acc: 0.8842 - val_loss: 0.5348 - val_acc: 0.8668\n",
      "Epoch 356/1000\n",
      "1649/1649 [==============================] - 0s 189us/step - loss: 0.4843 - acc: 0.8854 - val_loss: 0.5329 - val_acc: 0.8741\n",
      "Epoch 357/1000\n",
      "1649/1649 [==============================] - 0s 172us/step - loss: 0.4833 - acc: 0.8872 - val_loss: 0.5307 - val_acc: 0.8717\n",
      "Epoch 358/1000\n",
      "1649/1649 [==============================] - 0s 183us/step - loss: 0.4830 - acc: 0.8927 - val_loss: 0.5314 - val_acc: 0.8717\n",
      "Epoch 359/1000\n",
      "1649/1649 [==============================] - 0s 193us/step - loss: 0.4829 - acc: 0.8872 - val_loss: 0.5319 - val_acc: 0.8717\n",
      "Epoch 360/1000\n",
      "1649/1649 [==============================] - 0s 187us/step - loss: 0.4820 - acc: 0.8854 - val_loss: 0.5323 - val_acc: 0.8692\n",
      "Epoch 361/1000\n",
      "1649/1649 [==============================] - 0s 176us/step - loss: 0.4817 - acc: 0.8842 - val_loss: 0.5318 - val_acc: 0.8644\n",
      "Epoch 362/1000\n",
      "1649/1649 [==============================] - 0s 173us/step - loss: 0.4804 - acc: 0.8902 - val_loss: 0.5297 - val_acc: 0.8741\n",
      "Epoch 363/1000\n",
      "1649/1649 [==============================] - 0s 192us/step - loss: 0.4802 - acc: 0.8890 - val_loss: 0.5307 - val_acc: 0.8692\n",
      "Epoch 364/1000\n",
      "1649/1649 [==============================] - 0s 186us/step - loss: 0.4792 - acc: 0.8927 - val_loss: 0.5301 - val_acc: 0.8741\n",
      "Epoch 365/1000\n",
      "1649/1649 [==============================] - 0s 177us/step - loss: 0.4788 - acc: 0.8890 - val_loss: 0.5269 - val_acc: 0.8717\n",
      "Epoch 366/1000\n",
      "1649/1649 [==============================] - 0s 189us/step - loss: 0.4787 - acc: 0.8896 - val_loss: 0.5287 - val_acc: 0.8668\n",
      "Epoch 367/1000\n",
      "1649/1649 [==============================] - 0s 184us/step - loss: 0.4777 - acc: 0.8854 - val_loss: 0.5262 - val_acc: 0.8741\n",
      "Epoch 368/1000\n",
      "1649/1649 [==============================] - 0s 189us/step - loss: 0.4772 - acc: 0.8914 - val_loss: 0.5264 - val_acc: 0.8741\n",
      "Epoch 369/1000\n",
      "1649/1649 [==============================] - 0s 173us/step - loss: 0.4767 - acc: 0.8878 - val_loss: 0.5255 - val_acc: 0.8717\n",
      "Epoch 370/1000\n",
      "1649/1649 [==============================] - 0s 180us/step - loss: 0.4761 - acc: 0.8902 - val_loss: 0.5249 - val_acc: 0.8765\n",
      "Epoch 371/1000\n",
      "1649/1649 [==============================] - 0s 178us/step - loss: 0.4754 - acc: 0.8921 - val_loss: 0.5258 - val_acc: 0.8789\n",
      "Epoch 372/1000\n",
      "1649/1649 [==============================] - 0s 178us/step - loss: 0.4752 - acc: 0.8866 - val_loss: 0.5264 - val_acc: 0.8692\n",
      "Epoch 373/1000\n",
      "1649/1649 [==============================] - 0s 189us/step - loss: 0.4739 - acc: 0.8878 - val_loss: 0.5226 - val_acc: 0.8765\n",
      "Epoch 374/1000\n",
      "1649/1649 [==============================] - 0s 178us/step - loss: 0.4733 - acc: 0.8884 - val_loss: 0.5226 - val_acc: 0.8765\n",
      "Epoch 375/1000\n",
      "1649/1649 [==============================] - 0s 177us/step - loss: 0.4730 - acc: 0.8908 - val_loss: 0.5227 - val_acc: 0.8765\n",
      "Epoch 376/1000\n",
      "1649/1649 [==============================] - 0s 188us/step - loss: 0.4724 - acc: 0.8878 - val_loss: 0.5232 - val_acc: 0.8765\n",
      "Epoch 377/1000\n",
      "1649/1649 [==============================] - 0s 187us/step - loss: 0.4720 - acc: 0.8921 - val_loss: 0.5222 - val_acc: 0.8765\n",
      "Epoch 378/1000\n",
      "1649/1649 [==============================] - 0s 181us/step - loss: 0.4718 - acc: 0.8872 - val_loss: 0.5191 - val_acc: 0.8741\n",
      "Epoch 379/1000\n",
      "1649/1649 [==============================] - 0s 179us/step - loss: 0.4710 - acc: 0.8914 - val_loss: 0.5206 - val_acc: 0.8741\n",
      "Epoch 380/1000\n",
      "1649/1649 [==============================] - 0s 203us/step - loss: 0.4705 - acc: 0.8890 - val_loss: 0.5205 - val_acc: 0.8741\n",
      "Epoch 381/1000\n",
      "1649/1649 [==============================] - 0s 190us/step - loss: 0.4697 - acc: 0.8902 - val_loss: 0.5202 - val_acc: 0.8765\n",
      "Epoch 382/1000\n",
      "1649/1649 [==============================] - 0s 185us/step - loss: 0.4692 - acc: 0.8933 - val_loss: 0.5186 - val_acc: 0.8765\n",
      "Epoch 383/1000\n",
      "1649/1649 [==============================] - 0s 198us/step - loss: 0.4687 - acc: 0.8914 - val_loss: 0.5196 - val_acc: 0.8741\n",
      "Epoch 384/1000\n",
      "1649/1649 [==============================] - 0s 188us/step - loss: 0.4682 - acc: 0.8896 - val_loss: 0.5184 - val_acc: 0.8765\n",
      "Epoch 385/1000\n",
      "1649/1649 [==============================] - 0s 186us/step - loss: 0.4671 - acc: 0.8921 - val_loss: 0.5167 - val_acc: 0.8814\n",
      "Epoch 386/1000\n",
      "1649/1649 [==============================] - 0s 192us/step - loss: 0.4667 - acc: 0.8902 - val_loss: 0.5163 - val_acc: 0.8789\n",
      "Epoch 387/1000\n",
      "1649/1649 [==============================] - 0s 184us/step - loss: 0.4665 - acc: 0.8914 - val_loss: 0.5190 - val_acc: 0.8741\n",
      "Epoch 388/1000\n",
      "1649/1649 [==============================] - 0s 190us/step - loss: 0.4664 - acc: 0.8933 - val_loss: 0.5171 - val_acc: 0.8765\n",
      "Epoch 389/1000\n",
      "1649/1649 [==============================] - 0s 237us/step - loss: 0.4654 - acc: 0.8927 - val_loss: 0.5161 - val_acc: 0.8765\n",
      "Epoch 390/1000\n",
      "1649/1649 [==============================] - 0s 268us/step - loss: 0.4659 - acc: 0.8945 - val_loss: 0.5129 - val_acc: 0.8814\n",
      "Epoch 391/1000\n",
      "1649/1649 [==============================] - 0s 278us/step - loss: 0.4644 - acc: 0.8921 - val_loss: 0.5146 - val_acc: 0.8741\n",
      "Epoch 392/1000\n",
      "1649/1649 [==============================] - 0s 204us/step - loss: 0.4641 - acc: 0.8933 - val_loss: 0.5144 - val_acc: 0.8789\n",
      "Epoch 393/1000\n",
      "1649/1649 [==============================] - 0s 224us/step - loss: 0.4634 - acc: 0.8896 - val_loss: 0.5127 - val_acc: 0.8789\n",
      "Epoch 394/1000\n",
      "1649/1649 [==============================] - 0s 240us/step - loss: 0.4626 - acc: 0.8945 - val_loss: 0.5143 - val_acc: 0.8717\n",
      "Epoch 395/1000\n",
      "1649/1649 [==============================] - 0s 196us/step - loss: 0.4624 - acc: 0.8945 - val_loss: 0.5132 - val_acc: 0.8765\n",
      "Epoch 396/1000\n",
      "1649/1649 [==============================] - 0s 196us/step - loss: 0.4625 - acc: 0.8921 - val_loss: 0.5132 - val_acc: 0.8789\n",
      "Epoch 397/1000\n",
      "1649/1649 [==============================] - 0s 195us/step - loss: 0.4609 - acc: 0.8927 - val_loss: 0.5120 - val_acc: 0.8789\n",
      "Epoch 398/1000\n",
      "1649/1649 [==============================] - 0s 202us/step - loss: 0.4605 - acc: 0.8969 - val_loss: 0.5118 - val_acc: 0.8765\n",
      "Epoch 399/1000\n",
      "1649/1649 [==============================] - 0s 186us/step - loss: 0.4599 - acc: 0.8945 - val_loss: 0.5080 - val_acc: 0.8789\n",
      "Epoch 400/1000\n",
      "1649/1649 [==============================] - 0s 206us/step - loss: 0.4597 - acc: 0.8957 - val_loss: 0.5084 - val_acc: 0.8765\n",
      "Epoch 401/1000\n",
      "1649/1649 [==============================] - 0s 188us/step - loss: 0.4595 - acc: 0.8957 - val_loss: 0.5085 - val_acc: 0.8789\n",
      "Epoch 402/1000\n",
      "1649/1649 [==============================] - 0s 170us/step - loss: 0.4587 - acc: 0.8902 - val_loss: 0.5085 - val_acc: 0.8838\n",
      "Epoch 403/1000\n",
      "1649/1649 [==============================] - 0s 195us/step - loss: 0.4579 - acc: 0.8945 - val_loss: 0.5076 - val_acc: 0.8838\n",
      "Epoch 404/1000\n",
      "1649/1649 [==============================] - 0s 199us/step - loss: 0.4577 - acc: 0.8933 - val_loss: 0.5073 - val_acc: 0.8789\n",
      "Epoch 405/1000\n",
      "1649/1649 [==============================] - 0s 188us/step - loss: 0.4576 - acc: 0.8878 - val_loss: 0.5076 - val_acc: 0.8814\n",
      "Epoch 406/1000\n",
      "1649/1649 [==============================] - 0s 196us/step - loss: 0.4566 - acc: 0.8969 - val_loss: 0.5068 - val_acc: 0.8789\n",
      "Epoch 407/1000\n",
      "1649/1649 [==============================] - 0s 190us/step - loss: 0.4560 - acc: 0.8963 - val_loss: 0.5051 - val_acc: 0.8814\n",
      "Epoch 408/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1649/1649 [==============================] - 0s 177us/step - loss: 0.4556 - acc: 0.8975 - val_loss: 0.5048 - val_acc: 0.8838\n",
      "Epoch 409/1000\n",
      "1649/1649 [==============================] - 0s 174us/step - loss: 0.4554 - acc: 0.8939 - val_loss: 0.5050 - val_acc: 0.8838\n",
      "Epoch 410/1000\n",
      "1649/1649 [==============================] - 0s 173us/step - loss: 0.4544 - acc: 0.8957 - val_loss: 0.5040 - val_acc: 0.8838\n",
      "Epoch 411/1000\n",
      "1649/1649 [==============================] - 0s 202us/step - loss: 0.4539 - acc: 0.8981 - val_loss: 0.5051 - val_acc: 0.8789\n",
      "Epoch 412/1000\n",
      "1649/1649 [==============================] - 0s 189us/step - loss: 0.4537 - acc: 0.8945 - val_loss: 0.5055 - val_acc: 0.8789\n",
      "Epoch 413/1000\n",
      "1649/1649 [==============================] - 0s 206us/step - loss: 0.4530 - acc: 0.8975 - val_loss: 0.5041 - val_acc: 0.8789\n",
      "Epoch 414/1000\n",
      "1649/1649 [==============================] - 0s 223us/step - loss: 0.4524 - acc: 0.8963 - val_loss: 0.5018 - val_acc: 0.8789\n",
      "Epoch 415/1000\n",
      "1649/1649 [==============================] - 0s 198us/step - loss: 0.4520 - acc: 0.8957 - val_loss: 0.5022 - val_acc: 0.8789\n",
      "Epoch 416/1000\n",
      "1649/1649 [==============================] - 0s 210us/step - loss: 0.4517 - acc: 0.8945 - val_loss: 0.5003 - val_acc: 0.8814\n",
      "Epoch 417/1000\n",
      "1649/1649 [==============================] - 0s 213us/step - loss: 0.4519 - acc: 0.8951 - val_loss: 0.5001 - val_acc: 0.8789\n",
      "Epoch 418/1000\n",
      "1649/1649 [==============================] - 0s 195us/step - loss: 0.4509 - acc: 0.8933 - val_loss: 0.5007 - val_acc: 0.8838\n",
      "Epoch 419/1000\n",
      "1649/1649 [==============================] - 0s 206us/step - loss: 0.4500 - acc: 0.8975 - val_loss: 0.5015 - val_acc: 0.8814\n",
      "Epoch 420/1000\n",
      "1649/1649 [==============================] - 0s 234us/step - loss: 0.4493 - acc: 0.8963 - val_loss: 0.5019 - val_acc: 0.8789\n",
      "Epoch 421/1000\n",
      "1649/1649 [==============================] - 0s 184us/step - loss: 0.4490 - acc: 0.8987 - val_loss: 0.5007 - val_acc: 0.8838\n",
      "Epoch 422/1000\n",
      "1649/1649 [==============================] - 0s 175us/step - loss: 0.4486 - acc: 0.8957 - val_loss: 0.4996 - val_acc: 0.8838\n",
      "Epoch 423/1000\n",
      "1649/1649 [==============================] - 0s 218us/step - loss: 0.4481 - acc: 0.8987 - val_loss: 0.4998 - val_acc: 0.8789\n",
      "Epoch 424/1000\n",
      "1649/1649 [==============================] - 0s 186us/step - loss: 0.4483 - acc: 0.8975 - val_loss: 0.5004 - val_acc: 0.8765\n",
      "Epoch 425/1000\n",
      "1649/1649 [==============================] - 0s 181us/step - loss: 0.4469 - acc: 0.8963 - val_loss: 0.4968 - val_acc: 0.8814\n",
      "Epoch 426/1000\n",
      "1649/1649 [==============================] - 0s 199us/step - loss: 0.4467 - acc: 0.8969 - val_loss: 0.4981 - val_acc: 0.8838\n",
      "Epoch 427/1000\n",
      "1649/1649 [==============================] - 0s 200us/step - loss: 0.4461 - acc: 0.8987 - val_loss: 0.4962 - val_acc: 0.8814\n",
      "Epoch 428/1000\n",
      "1649/1649 [==============================] - 0s 211us/step - loss: 0.4458 - acc: 0.8999 - val_loss: 0.4971 - val_acc: 0.8838\n",
      "Epoch 429/1000\n",
      "1649/1649 [==============================] - 0s 206us/step - loss: 0.4452 - acc: 0.8999 - val_loss: 0.4964 - val_acc: 0.8789\n",
      "Epoch 430/1000\n",
      "1649/1649 [==============================] - 0s 202us/step - loss: 0.4449 - acc: 0.8981 - val_loss: 0.4938 - val_acc: 0.8838\n",
      "Epoch 431/1000\n",
      "1649/1649 [==============================] - 0s 195us/step - loss: 0.4444 - acc: 0.8975 - val_loss: 0.4953 - val_acc: 0.8838\n",
      "Epoch 432/1000\n",
      "1649/1649 [==============================] - 0s 200us/step - loss: 0.4440 - acc: 0.8987 - val_loss: 0.4942 - val_acc: 0.8789\n",
      "Epoch 433/1000\n",
      "1649/1649 [==============================] - 0s 208us/step - loss: 0.4434 - acc: 0.9024 - val_loss: 0.4948 - val_acc: 0.8838\n",
      "Epoch 434/1000\n",
      "1649/1649 [==============================] - 0s 203us/step - loss: 0.4431 - acc: 0.8969 - val_loss: 0.4930 - val_acc: 0.8814\n",
      "Epoch 435/1000\n",
      "1649/1649 [==============================] - 0s 209us/step - loss: 0.4426 - acc: 0.8999 - val_loss: 0.4942 - val_acc: 0.8814\n",
      "Epoch 436/1000\n",
      "1649/1649 [==============================] - 0s 238us/step - loss: 0.4419 - acc: 0.8981 - val_loss: 0.4922 - val_acc: 0.8814\n",
      "Epoch 437/1000\n",
      "1649/1649 [==============================] - 0s 295us/step - loss: 0.4415 - acc: 0.9012 - val_loss: 0.4927 - val_acc: 0.8814\n",
      "Epoch 438/1000\n",
      "1649/1649 [==============================] - 0s 294us/step - loss: 0.4412 - acc: 0.8987 - val_loss: 0.4913 - val_acc: 0.8838\n",
      "Epoch 439/1000\n",
      "1649/1649 [==============================] - 0s 285us/step - loss: 0.4407 - acc: 0.8993 - val_loss: 0.4914 - val_acc: 0.8862\n",
      "Epoch 440/1000\n",
      "1649/1649 [==============================] - 0s 278us/step - loss: 0.4403 - acc: 0.8993 - val_loss: 0.4919 - val_acc: 0.8838\n",
      "Epoch 441/1000\n",
      "1649/1649 [==============================] - 0s 274us/step - loss: 0.4400 - acc: 0.8987 - val_loss: 0.4900 - val_acc: 0.8838\n",
      "Epoch 442/1000\n",
      "1649/1649 [==============================] - 0s 241us/step - loss: 0.4392 - acc: 0.9024 - val_loss: 0.4915 - val_acc: 0.8838\n",
      "Epoch 443/1000\n",
      "1649/1649 [==============================] - 0s 221us/step - loss: 0.4385 - acc: 0.9005 - val_loss: 0.4888 - val_acc: 0.8838\n",
      "Epoch 444/1000\n",
      "1649/1649 [==============================] - 0s 226us/step - loss: 0.4385 - acc: 0.8987 - val_loss: 0.4885 - val_acc: 0.8838\n",
      "Epoch 445/1000\n",
      "1649/1649 [==============================] - 0s 201us/step - loss: 0.4388 - acc: 0.8993 - val_loss: 0.4877 - val_acc: 0.8814\n",
      "Epoch 446/1000\n",
      "1649/1649 [==============================] - 0s 198us/step - loss: 0.4375 - acc: 0.8975 - val_loss: 0.4891 - val_acc: 0.8814\n",
      "Epoch 447/1000\n",
      "1649/1649 [==============================] - 0s 213us/step - loss: 0.4373 - acc: 0.8993 - val_loss: 0.4887 - val_acc: 0.8838\n",
      "Epoch 448/1000\n",
      "1649/1649 [==============================] - 0s 226us/step - loss: 0.4368 - acc: 0.9005 - val_loss: 0.4887 - val_acc: 0.8838\n",
      "Epoch 449/1000\n",
      "1649/1649 [==============================] - 0s 235us/step - loss: 0.4368 - acc: 0.8987 - val_loss: 0.4876 - val_acc: 0.8814\n",
      "Epoch 450/1000\n",
      "1649/1649 [==============================] - 0s 218us/step - loss: 0.4359 - acc: 0.8999 - val_loss: 0.4875 - val_acc: 0.8838\n",
      "Epoch 451/1000\n",
      "1649/1649 [==============================] - 0s 224us/step - loss: 0.4356 - acc: 0.8999 - val_loss: 0.4855 - val_acc: 0.8862\n",
      "Epoch 452/1000\n",
      "1649/1649 [==============================] - 0s 220us/step - loss: 0.4352 - acc: 0.9024 - val_loss: 0.4876 - val_acc: 0.8838\n",
      "Epoch 453/1000\n",
      "1649/1649 [==============================] - 0s 221us/step - loss: 0.4347 - acc: 0.8999 - val_loss: 0.4872 - val_acc: 0.8814\n",
      "Epoch 454/1000\n",
      "1649/1649 [==============================] - 0s 208us/step - loss: 0.4343 - acc: 0.9012 - val_loss: 0.4854 - val_acc: 0.8838\n",
      "Epoch 455/1000\n",
      "1649/1649 [==============================] - 0s 208us/step - loss: 0.4334 - acc: 0.9018 - val_loss: 0.4843 - val_acc: 0.8886\n",
      "Epoch 456/1000\n",
      "1649/1649 [==============================] - 0s 220us/step - loss: 0.4334 - acc: 0.9005 - val_loss: 0.4867 - val_acc: 0.8814\n",
      "Epoch 457/1000\n",
      "1649/1649 [==============================] - 0s 202us/step - loss: 0.4332 - acc: 0.8963 - val_loss: 0.4825 - val_acc: 0.8862\n",
      "Epoch 458/1000\n",
      "1649/1649 [==============================] - 0s 207us/step - loss: 0.4321 - acc: 0.9024 - val_loss: 0.4849 - val_acc: 0.8838\n",
      "Epoch 459/1000\n",
      "1649/1649 [==============================] - 0s 204us/step - loss: 0.4322 - acc: 0.9018 - val_loss: 0.4855 - val_acc: 0.8814\n",
      "Epoch 460/1000\n",
      "1649/1649 [==============================] - 0s 221us/step - loss: 0.4318 - acc: 0.8987 - val_loss: 0.4817 - val_acc: 0.8862\n",
      "Epoch 461/1000\n",
      "1649/1649 [==============================] - 0s 235us/step - loss: 0.4309 - acc: 0.9018 - val_loss: 0.4816 - val_acc: 0.8862\n",
      "Epoch 462/1000\n",
      "1649/1649 [==============================] - 0s 215us/step - loss: 0.4311 - acc: 0.9012 - val_loss: 0.4819 - val_acc: 0.8838\n",
      "Epoch 463/1000\n",
      "1649/1649 [==============================] - 0s 198us/step - loss: 0.4308 - acc: 0.8999 - val_loss: 0.4807 - val_acc: 0.8862\n",
      "Epoch 464/1000\n",
      "1649/1649 [==============================] - 0s 206us/step - loss: 0.4300 - acc: 0.8999 - val_loss: 0.4811 - val_acc: 0.8862\n",
      "Epoch 465/1000\n",
      "1649/1649 [==============================] - 0s 231us/step - loss: 0.4293 - acc: 0.9012 - val_loss: 0.4802 - val_acc: 0.8862\n",
      "Epoch 466/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1649/1649 [==============================] - 0s 188us/step - loss: 0.4286 - acc: 0.9036 - val_loss: 0.4821 - val_acc: 0.8838\n",
      "Epoch 467/1000\n",
      "1649/1649 [==============================] - 0s 182us/step - loss: 0.4282 - acc: 0.9036 - val_loss: 0.4791 - val_acc: 0.8862\n",
      "Epoch 468/1000\n",
      "1649/1649 [==============================] - 0s 188us/step - loss: 0.4283 - acc: 0.9030 - val_loss: 0.4803 - val_acc: 0.8862\n",
      "Epoch 469/1000\n",
      "1649/1649 [==============================] - 0s 176us/step - loss: 0.4281 - acc: 0.9030 - val_loss: 0.4805 - val_acc: 0.8838\n",
      "Epoch 470/1000\n",
      "1649/1649 [==============================] - 0s 175us/step - loss: 0.4272 - acc: 0.9012 - val_loss: 0.4798 - val_acc: 0.8862\n",
      "Epoch 471/1000\n",
      "1649/1649 [==============================] - 0s 170us/step - loss: 0.4269 - acc: 0.9018 - val_loss: 0.4799 - val_acc: 0.8886\n",
      "Epoch 472/1000\n",
      "1649/1649 [==============================] - 0s 183us/step - loss: 0.4267 - acc: 0.9030 - val_loss: 0.4774 - val_acc: 0.8862\n",
      "Epoch 473/1000\n",
      "1649/1649 [==============================] - 0s 167us/step - loss: 0.4265 - acc: 0.9048 - val_loss: 0.4781 - val_acc: 0.8886\n",
      "Epoch 474/1000\n",
      "1649/1649 [==============================] - 0s 172us/step - loss: 0.4255 - acc: 0.9024 - val_loss: 0.4766 - val_acc: 0.8886\n",
      "Epoch 475/1000\n",
      "1649/1649 [==============================] - 0s 185us/step - loss: 0.4256 - acc: 0.9036 - val_loss: 0.4755 - val_acc: 0.8886\n",
      "Epoch 476/1000\n",
      "1649/1649 [==============================] - 0s 174us/step - loss: 0.4248 - acc: 0.9030 - val_loss: 0.4774 - val_acc: 0.8886\n",
      "Epoch 477/1000\n",
      "1649/1649 [==============================] - 0s 187us/step - loss: 0.4246 - acc: 0.9018 - val_loss: 0.4743 - val_acc: 0.8910\n",
      "Epoch 478/1000\n",
      "1649/1649 [==============================] - 0s 170us/step - loss: 0.4245 - acc: 0.9030 - val_loss: 0.4753 - val_acc: 0.8886\n",
      "Epoch 479/1000\n",
      "1649/1649 [==============================] - 0s 195us/step - loss: 0.4233 - acc: 0.9018 - val_loss: 0.4757 - val_acc: 0.8886\n",
      "Epoch 480/1000\n",
      "1649/1649 [==============================] - 0s 178us/step - loss: 0.4233 - acc: 0.9042 - val_loss: 0.4761 - val_acc: 0.8862\n",
      "Epoch 481/1000\n",
      "1649/1649 [==============================] - 0s 185us/step - loss: 0.4234 - acc: 0.8981 - val_loss: 0.4757 - val_acc: 0.8886\n",
      "Epoch 482/1000\n",
      "1649/1649 [==============================] - 0s 231us/step - loss: 0.4231 - acc: 0.8999 - val_loss: 0.4741 - val_acc: 0.8886\n",
      "Epoch 483/1000\n",
      "1649/1649 [==============================] - 0s 214us/step - loss: 0.4217 - acc: 0.9030 - val_loss: 0.4737 - val_acc: 0.8886\n",
      "Epoch 484/1000\n",
      "1649/1649 [==============================] - 0s 246us/step - loss: 0.4216 - acc: 0.9054 - val_loss: 0.4740 - val_acc: 0.8886\n",
      "Epoch 485/1000\n",
      "1649/1649 [==============================] - 0s 216us/step - loss: 0.4213 - acc: 0.9024 - val_loss: 0.4742 - val_acc: 0.8862\n",
      "Epoch 486/1000\n",
      "1649/1649 [==============================] - 0s 168us/step - loss: 0.4210 - acc: 0.9048 - val_loss: 0.4709 - val_acc: 0.8910\n",
      "Epoch 487/1000\n",
      "1649/1649 [==============================] - 0s 246us/step - loss: 0.4206 - acc: 0.9042 - val_loss: 0.4715 - val_acc: 0.8862\n",
      "Epoch 488/1000\n",
      "1649/1649 [==============================] - 0s 215us/step - loss: 0.4204 - acc: 0.9024 - val_loss: 0.4717 - val_acc: 0.8886\n",
      "Epoch 489/1000\n",
      "1649/1649 [==============================] - 0s 184us/step - loss: 0.4200 - acc: 0.9030 - val_loss: 0.4698 - val_acc: 0.8910\n",
      "Epoch 490/1000\n",
      "1649/1649 [==============================] - 0s 169us/step - loss: 0.4190 - acc: 0.9054 - val_loss: 0.4721 - val_acc: 0.8886\n",
      "Epoch 491/1000\n",
      "1649/1649 [==============================] - 0s 193us/step - loss: 0.4188 - acc: 0.9060 - val_loss: 0.4702 - val_acc: 0.8886\n",
      "Epoch 492/1000\n",
      "1649/1649 [==============================] - 0s 170us/step - loss: 0.4183 - acc: 0.9054 - val_loss: 0.4710 - val_acc: 0.8886\n",
      "Epoch 493/1000\n",
      "1649/1649 [==============================] - 0s 172us/step - loss: 0.4180 - acc: 0.9054 - val_loss: 0.4699 - val_acc: 0.8886\n",
      "Epoch 494/1000\n",
      "1649/1649 [==============================] - 0s 176us/step - loss: 0.4177 - acc: 0.9048 - val_loss: 0.4693 - val_acc: 0.8886\n",
      "Epoch 495/1000\n",
      "1649/1649 [==============================] - 0s 203us/step - loss: 0.4172 - acc: 0.9036 - val_loss: 0.4693 - val_acc: 0.8886\n",
      "Epoch 496/1000\n",
      "1649/1649 [==============================] - 0s 176us/step - loss: 0.4169 - acc: 0.9042 - val_loss: 0.4688 - val_acc: 0.8886\n",
      "Epoch 497/1000\n",
      "1649/1649 [==============================] - 0s 176us/step - loss: 0.4165 - acc: 0.9054 - val_loss: 0.4704 - val_acc: 0.8862\n",
      "Epoch 498/1000\n",
      "1649/1649 [==============================] - 0s 188us/step - loss: 0.4166 - acc: 0.9018 - val_loss: 0.4693 - val_acc: 0.8886\n",
      "Epoch 499/1000\n",
      "1649/1649 [==============================] - 0s 178us/step - loss: 0.4162 - acc: 0.9060 - val_loss: 0.4667 - val_acc: 0.8910\n",
      "Epoch 500/1000\n",
      "1649/1649 [==============================] - 0s 185us/step - loss: 0.4155 - acc: 0.9060 - val_loss: 0.4684 - val_acc: 0.8886\n",
      "Epoch 501/1000\n",
      "1649/1649 [==============================] - 0s 195us/step - loss: 0.4151 - acc: 0.9066 - val_loss: 0.4673 - val_acc: 0.8886\n",
      "Epoch 502/1000\n",
      "1649/1649 [==============================] - 0s 195us/step - loss: 0.4145 - acc: 0.9060 - val_loss: 0.4671 - val_acc: 0.8886\n",
      "Epoch 503/1000\n",
      "1649/1649 [==============================] - 0s 200us/step - loss: 0.4152 - acc: 0.9054 - val_loss: 0.4675 - val_acc: 0.8886\n",
      "Epoch 504/1000\n",
      "1649/1649 [==============================] - 0s 231us/step - loss: 0.4141 - acc: 0.9048 - val_loss: 0.4671 - val_acc: 0.8886\n",
      "Epoch 505/1000\n",
      "1649/1649 [==============================] - 0s 272us/step - loss: 0.4137 - acc: 0.9054 - val_loss: 0.4657 - val_acc: 0.8886\n",
      "Epoch 506/1000\n",
      "1649/1649 [==============================] - 0s 224us/step - loss: 0.4132 - acc: 0.9060 - val_loss: 0.4649 - val_acc: 0.8886\n",
      "Epoch 507/1000\n",
      "1649/1649 [==============================] - 0s 283us/step - loss: 0.4130 - acc: 0.9054 - val_loss: 0.4645 - val_acc: 0.8886\n",
      "Epoch 508/1000\n",
      "1649/1649 [==============================] - 0s 242us/step - loss: 0.4125 - acc: 0.9072 - val_loss: 0.4642 - val_acc: 0.8886\n",
      "Epoch 509/1000\n",
      "1649/1649 [==============================] - 0s 243us/step - loss: 0.4125 - acc: 0.9030 - val_loss: 0.4646 - val_acc: 0.8886\n",
      "Epoch 510/1000\n",
      "1649/1649 [==============================] - 0s 238us/step - loss: 0.4118 - acc: 0.9072 - val_loss: 0.4647 - val_acc: 0.8886\n",
      "Epoch 511/1000\n",
      "1649/1649 [==============================] - 0s 237us/step - loss: 0.4114 - acc: 0.9066 - val_loss: 0.4634 - val_acc: 0.8886\n",
      "Epoch 512/1000\n",
      "1649/1649 [==============================] - 0s 264us/step - loss: 0.4109 - acc: 0.9054 - val_loss: 0.4640 - val_acc: 0.8886\n",
      "Epoch 513/1000\n",
      "1649/1649 [==============================] - 0s 238us/step - loss: 0.4106 - acc: 0.9078 - val_loss: 0.4632 - val_acc: 0.8886\n",
      "Epoch 514/1000\n",
      "1649/1649 [==============================] - 0s 233us/step - loss: 0.4106 - acc: 0.9072 - val_loss: 0.4626 - val_acc: 0.8886\n",
      "Epoch 515/1000\n",
      "1649/1649 [==============================] - 0s 220us/step - loss: 0.4102 - acc: 0.9048 - val_loss: 0.4615 - val_acc: 0.8886\n",
      "Epoch 516/1000\n",
      "1649/1649 [==============================] - 0s 230us/step - loss: 0.4098 - acc: 0.9066 - val_loss: 0.4632 - val_acc: 0.8886\n",
      "Epoch 517/1000\n",
      "1649/1649 [==============================] - 0s 232us/step - loss: 0.4093 - acc: 0.9096 - val_loss: 0.4630 - val_acc: 0.8886\n",
      "Epoch 518/1000\n",
      "1649/1649 [==============================] - 0s 223us/step - loss: 0.4092 - acc: 0.9066 - val_loss: 0.4623 - val_acc: 0.8886\n",
      "Epoch 519/1000\n",
      "1649/1649 [==============================] - 0s 247us/step - loss: 0.4088 - acc: 0.9054 - val_loss: 0.4614 - val_acc: 0.8886\n",
      "Epoch 520/1000\n",
      "1649/1649 [==============================] - 0s 234us/step - loss: 0.4078 - acc: 0.9072 - val_loss: 0.4606 - val_acc: 0.8886\n",
      "Epoch 521/1000\n",
      "1649/1649 [==============================] - 0s 211us/step - loss: 0.4076 - acc: 0.9060 - val_loss: 0.4589 - val_acc: 0.8886\n",
      "Epoch 522/1000\n",
      "1649/1649 [==============================] - 0s 232us/step - loss: 0.4075 - acc: 0.9048 - val_loss: 0.4587 - val_acc: 0.8910\n",
      "Epoch 523/1000\n",
      "1649/1649 [==============================] - 0s 222us/step - loss: 0.4077 - acc: 0.9060 - val_loss: 0.4609 - val_acc: 0.8886\n",
      "Epoch 524/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1649/1649 [==============================] - 0s 196us/step - loss: 0.4066 - acc: 0.9066 - val_loss: 0.4598 - val_acc: 0.8886\n",
      "Epoch 525/1000\n",
      "1649/1649 [==============================] - 0s 214us/step - loss: 0.4066 - acc: 0.9084 - val_loss: 0.4602 - val_acc: 0.8910\n",
      "Epoch 526/1000\n",
      "1649/1649 [==============================] - 0s 197us/step - loss: 0.4060 - acc: 0.9066 - val_loss: 0.4573 - val_acc: 0.8910\n",
      "Epoch 527/1000\n",
      "1649/1649 [==============================] - 0s 241us/step - loss: 0.4057 - acc: 0.9078 - val_loss: 0.4589 - val_acc: 0.8886\n",
      "Epoch 528/1000\n",
      "1649/1649 [==============================] - 0s 270us/step - loss: 0.4056 - acc: 0.9078 - val_loss: 0.4573 - val_acc: 0.8910\n",
      "Epoch 529/1000\n",
      "1649/1649 [==============================] - 0s 272us/step - loss: 0.4047 - acc: 0.9084 - val_loss: 0.4571 - val_acc: 0.8910\n",
      "Epoch 530/1000\n",
      "1649/1649 [==============================] - 0s 211us/step - loss: 0.4046 - acc: 0.9066 - val_loss: 0.4566 - val_acc: 0.8910\n",
      "Epoch 531/1000\n",
      "1649/1649 [==============================] - 0s 215us/step - loss: 0.4045 - acc: 0.9072 - val_loss: 0.4560 - val_acc: 0.8910\n",
      "Epoch 532/1000\n",
      "1649/1649 [==============================] - 0s 228us/step - loss: 0.4046 - acc: 0.9036 - val_loss: 0.4554 - val_acc: 0.8910\n",
      "Epoch 533/1000\n",
      "1649/1649 [==============================] - 0s 195us/step - loss: 0.4034 - acc: 0.9072 - val_loss: 0.4563 - val_acc: 0.8886\n",
      "Epoch 534/1000\n",
      "1649/1649 [==============================] - 0s 196us/step - loss: 0.4033 - acc: 0.9090 - val_loss: 0.4567 - val_acc: 0.8886\n",
      "Epoch 535/1000\n",
      "1649/1649 [==============================] - 0s 200us/step - loss: 0.4031 - acc: 0.9072 - val_loss: 0.4545 - val_acc: 0.8886\n",
      "Epoch 536/1000\n",
      "1649/1649 [==============================] - 0s 222us/step - loss: 0.4025 - acc: 0.9066 - val_loss: 0.4555 - val_acc: 0.8886\n",
      "Epoch 537/1000\n",
      "1649/1649 [==============================] - 0s 188us/step - loss: 0.4025 - acc: 0.9072 - val_loss: 0.4548 - val_acc: 0.8935\n",
      "Epoch 538/1000\n",
      "1649/1649 [==============================] - 0s 200us/step - loss: 0.4017 - acc: 0.9054 - val_loss: 0.4552 - val_acc: 0.8910\n",
      "Epoch 539/1000\n",
      "1649/1649 [==============================] - 0s 215us/step - loss: 0.4015 - acc: 0.9084 - val_loss: 0.4541 - val_acc: 0.8910\n",
      "Epoch 540/1000\n",
      "1649/1649 [==============================] - 0s 192us/step - loss: 0.4011 - acc: 0.9066 - val_loss: 0.4538 - val_acc: 0.8886\n",
      "Epoch 541/1000\n",
      "1649/1649 [==============================] - 0s 190us/step - loss: 0.4010 - acc: 0.9072 - val_loss: 0.4524 - val_acc: 0.8910\n",
      "Epoch 542/1000\n",
      "1649/1649 [==============================] - 0s 202us/step - loss: 0.4006 - acc: 0.9066 - val_loss: 0.4526 - val_acc: 0.8910\n",
      "Epoch 543/1000\n",
      "1649/1649 [==============================] - 0s 187us/step - loss: 0.4003 - acc: 0.9078 - val_loss: 0.4521 - val_acc: 0.8910\n",
      "Epoch 544/1000\n",
      "1649/1649 [==============================] - 0s 193us/step - loss: 0.4004 - acc: 0.9078 - val_loss: 0.4509 - val_acc: 0.8910\n",
      "Epoch 545/1000\n",
      "1649/1649 [==============================] - 0s 196us/step - loss: 0.3995 - acc: 0.9084 - val_loss: 0.4522 - val_acc: 0.8910\n",
      "Epoch 546/1000\n",
      "1649/1649 [==============================] - 0s 195us/step - loss: 0.3991 - acc: 0.9090 - val_loss: 0.4520 - val_acc: 0.8935\n",
      "Epoch 547/1000\n",
      "1649/1649 [==============================] - 0s 181us/step - loss: 0.3993 - acc: 0.9066 - val_loss: 0.4524 - val_acc: 0.8886\n",
      "Epoch 548/1000\n",
      "1649/1649 [==============================] - 0s 196us/step - loss: 0.3984 - acc: 0.9096 - val_loss: 0.4526 - val_acc: 0.8910\n",
      "Epoch 549/1000\n",
      "1649/1649 [==============================] - 0s 209us/step - loss: 0.3984 - acc: 0.9115 - val_loss: 0.4520 - val_acc: 0.8886\n",
      "Epoch 550/1000\n",
      "1649/1649 [==============================] - 0s 187us/step - loss: 0.3978 - acc: 0.9102 - val_loss: 0.4518 - val_acc: 0.8910\n",
      "Epoch 551/1000\n",
      "1649/1649 [==============================] - 0s 192us/step - loss: 0.3975 - acc: 0.9090 - val_loss: 0.4511 - val_acc: 0.8910\n",
      "Epoch 552/1000\n",
      "1649/1649 [==============================] - 0s 195us/step - loss: 0.3974 - acc: 0.9084 - val_loss: 0.4496 - val_acc: 0.8886\n",
      "Epoch 553/1000\n",
      "1649/1649 [==============================] - 0s 196us/step - loss: 0.3970 - acc: 0.9121 - val_loss: 0.4513 - val_acc: 0.8910\n",
      "Epoch 554/1000\n",
      "1649/1649 [==============================] - 0s 195us/step - loss: 0.3966 - acc: 0.9084 - val_loss: 0.4496 - val_acc: 0.8886\n",
      "Epoch 555/1000\n",
      "1649/1649 [==============================] - 0s 195us/step - loss: 0.3962 - acc: 0.9084 - val_loss: 0.4497 - val_acc: 0.8910\n",
      "Epoch 556/1000\n",
      "1649/1649 [==============================] - 0s 188us/step - loss: 0.3956 - acc: 0.9084 - val_loss: 0.4483 - val_acc: 0.8886\n",
      "Epoch 557/1000\n",
      "1649/1649 [==============================] - 0s 190us/step - loss: 0.3953 - acc: 0.9090 - val_loss: 0.4495 - val_acc: 0.8886\n",
      "Epoch 558/1000\n",
      "1649/1649 [==============================] - 0s 196us/step - loss: 0.3952 - acc: 0.9115 - val_loss: 0.4487 - val_acc: 0.8910\n",
      "Epoch 559/1000\n",
      "1649/1649 [==============================] - 0s 195us/step - loss: 0.3951 - acc: 0.9066 - val_loss: 0.4482 - val_acc: 0.8935\n",
      "Epoch 560/1000\n",
      "1649/1649 [==============================] - 0s 198us/step - loss: 0.3946 - acc: 0.9102 - val_loss: 0.4490 - val_acc: 0.8935\n",
      "Epoch 561/1000\n",
      "1649/1649 [==============================] - 0s 196us/step - loss: 0.3946 - acc: 0.9072 - val_loss: 0.4474 - val_acc: 0.8910\n",
      "Epoch 562/1000\n",
      "1649/1649 [==============================] - 0s 200us/step - loss: 0.3945 - acc: 0.9096 - val_loss: 0.4482 - val_acc: 0.8910\n",
      "Epoch 563/1000\n",
      "1649/1649 [==============================] - 0s 198us/step - loss: 0.3935 - acc: 0.9078 - val_loss: 0.4455 - val_acc: 0.8910\n",
      "Epoch 564/1000\n",
      "1649/1649 [==============================] - 0s 204us/step - loss: 0.3936 - acc: 0.9090 - val_loss: 0.4490 - val_acc: 0.8910\n",
      "Epoch 565/1000\n",
      "1649/1649 [==============================] - 0s 197us/step - loss: 0.3929 - acc: 0.9096 - val_loss: 0.4468 - val_acc: 0.8886\n",
      "Epoch 566/1000\n",
      "1649/1649 [==============================] - 0s 191us/step - loss: 0.3927 - acc: 0.9090 - val_loss: 0.4462 - val_acc: 0.8910\n",
      "Epoch 567/1000\n",
      "1649/1649 [==============================] - 0s 196us/step - loss: 0.3920 - acc: 0.9109 - val_loss: 0.4451 - val_acc: 0.8910\n",
      "Epoch 568/1000\n",
      "1649/1649 [==============================] - 0s 207us/step - loss: 0.3916 - acc: 0.9078 - val_loss: 0.4448 - val_acc: 0.8910\n",
      "Epoch 569/1000\n",
      "1649/1649 [==============================] - 0s 200us/step - loss: 0.3920 - acc: 0.9084 - val_loss: 0.4432 - val_acc: 0.8910\n",
      "Epoch 570/1000\n",
      "1649/1649 [==============================] - 0s 186us/step - loss: 0.3913 - acc: 0.9090 - val_loss: 0.4441 - val_acc: 0.8910\n",
      "Epoch 571/1000\n",
      "1649/1649 [==============================] - 0s 197us/step - loss: 0.3910 - acc: 0.9084 - val_loss: 0.4423 - val_acc: 0.8910\n",
      "Epoch 572/1000\n",
      "1649/1649 [==============================] - 0s 200us/step - loss: 0.3907 - acc: 0.9090 - val_loss: 0.4465 - val_acc: 0.8910\n",
      "Epoch 573/1000\n",
      "1649/1649 [==============================] - 0s 191us/step - loss: 0.3907 - acc: 0.9090 - val_loss: 0.4452 - val_acc: 0.8886\n",
      "Epoch 574/1000\n",
      "1649/1649 [==============================] - 0s 247us/step - loss: 0.3910 - acc: 0.9054 - val_loss: 0.4443 - val_acc: 0.8910\n",
      "Epoch 575/1000\n",
      "1649/1649 [==============================] - 0s 263us/step - loss: 0.3899 - acc: 0.9096 - val_loss: 0.4422 - val_acc: 0.8910\n",
      "Epoch 576/1000\n",
      "1649/1649 [==============================] - 0s 250us/step - loss: 0.3898 - acc: 0.9096 - val_loss: 0.4435 - val_acc: 0.8935\n",
      "Epoch 577/1000\n",
      "1649/1649 [==============================] - 0s 252us/step - loss: 0.3895 - acc: 0.9096 - val_loss: 0.4431 - val_acc: 0.8935\n",
      "Epoch 578/1000\n",
      "1649/1649 [==============================] - 0s 197us/step - loss: 0.3888 - acc: 0.9133 - val_loss: 0.4433 - val_acc: 0.8886\n",
      "Epoch 579/1000\n",
      "1649/1649 [==============================] - 0s 271us/step - loss: 0.3888 - acc: 0.9115 - val_loss: 0.4433 - val_acc: 0.8910\n",
      "Epoch 580/1000\n",
      "1649/1649 [==============================] - 0s 240us/step - loss: 0.3885 - acc: 0.9078 - val_loss: 0.4421 - val_acc: 0.8886\n",
      "Epoch 581/1000\n",
      "1649/1649 [==============================] - 0s 196us/step - loss: 0.3878 - acc: 0.9102 - val_loss: 0.4411 - val_acc: 0.8935\n",
      "Epoch 582/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1649/1649 [==============================] - 0s 190us/step - loss: 0.3879 - acc: 0.9072 - val_loss: 0.4411 - val_acc: 0.8935\n",
      "Epoch 583/1000\n",
      "1649/1649 [==============================] - 0s 182us/step - loss: 0.3875 - acc: 0.9078 - val_loss: 0.4420 - val_acc: 0.8910\n",
      "Epoch 584/1000\n",
      "1649/1649 [==============================] - 0s 175us/step - loss: 0.3872 - acc: 0.9121 - val_loss: 0.4407 - val_acc: 0.8910\n",
      "Epoch 585/1000\n",
      "1649/1649 [==============================] - 0s 198us/step - loss: 0.3867 - acc: 0.9121 - val_loss: 0.4399 - val_acc: 0.8935\n",
      "Epoch 586/1000\n",
      "1649/1649 [==============================] - 0s 191us/step - loss: 0.3863 - acc: 0.9090 - val_loss: 0.4403 - val_acc: 0.8910\n",
      "Epoch 587/1000\n",
      "1649/1649 [==============================] - 0s 175us/step - loss: 0.3858 - acc: 0.9115 - val_loss: 0.4392 - val_acc: 0.8935\n",
      "Epoch 588/1000\n",
      "1649/1649 [==============================] - 0s 186us/step - loss: 0.3859 - acc: 0.9115 - val_loss: 0.4392 - val_acc: 0.8935\n",
      "Epoch 589/1000\n",
      "1649/1649 [==============================] - 0s 176us/step - loss: 0.3853 - acc: 0.9084 - val_loss: 0.4393 - val_acc: 0.8935\n",
      "Epoch 590/1000\n",
      "1649/1649 [==============================] - 0s 177us/step - loss: 0.3850 - acc: 0.9115 - val_loss: 0.4388 - val_acc: 0.8886\n",
      "Epoch 591/1000\n",
      "1649/1649 [==============================] - 0s 175us/step - loss: 0.3848 - acc: 0.9121 - val_loss: 0.4382 - val_acc: 0.8910\n",
      "Epoch 592/1000\n",
      "1649/1649 [==============================] - 0s 186us/step - loss: 0.3849 - acc: 0.9084 - val_loss: 0.4378 - val_acc: 0.8935\n",
      "Epoch 593/1000\n",
      "1649/1649 [==============================] - 0s 175us/step - loss: 0.3844 - acc: 0.9102 - val_loss: 0.4389 - val_acc: 0.8910\n",
      "Epoch 594/1000\n",
      "1649/1649 [==============================] - 0s 175us/step - loss: 0.3840 - acc: 0.9121 - val_loss: 0.4381 - val_acc: 0.8935\n",
      "Epoch 595/1000\n",
      "1649/1649 [==============================] - 0s 198us/step - loss: 0.3834 - acc: 0.9121 - val_loss: 0.4373 - val_acc: 0.8935\n",
      "Epoch 596/1000\n",
      "1649/1649 [==============================] - 0s 183us/step - loss: 0.3830 - acc: 0.9096 - val_loss: 0.4377 - val_acc: 0.8886\n",
      "Epoch 597/1000\n",
      "1649/1649 [==============================] - 0s 185us/step - loss: 0.3831 - acc: 0.9096 - val_loss: 0.4369 - val_acc: 0.8935\n",
      "Epoch 598/1000\n",
      "1649/1649 [==============================] - 0s 175us/step - loss: 0.3829 - acc: 0.9096 - val_loss: 0.4359 - val_acc: 0.8935\n",
      "Epoch 599/1000\n",
      "1649/1649 [==============================] - 0s 200us/step - loss: 0.3828 - acc: 0.9133 - val_loss: 0.4365 - val_acc: 0.8935\n",
      "Epoch 600/1000\n",
      "1649/1649 [==============================] - 0s 186us/step - loss: 0.3822 - acc: 0.9102 - val_loss: 0.4355 - val_acc: 0.8935\n",
      "Epoch 601/1000\n",
      "1649/1649 [==============================] - 0s 176us/step - loss: 0.3821 - acc: 0.9109 - val_loss: 0.4364 - val_acc: 0.8910\n",
      "Epoch 602/1000\n",
      "1649/1649 [==============================] - 0s 203us/step - loss: 0.3818 - acc: 0.9115 - val_loss: 0.4362 - val_acc: 0.8910\n",
      "Epoch 603/1000\n",
      "1649/1649 [==============================] - 0s 192us/step - loss: 0.3816 - acc: 0.9127 - val_loss: 0.4349 - val_acc: 0.8910\n",
      "Epoch 604/1000\n",
      "1649/1649 [==============================] - 0s 186us/step - loss: 0.3814 - acc: 0.9127 - val_loss: 0.4342 - val_acc: 0.8935\n",
      "Epoch 605/1000\n",
      "1649/1649 [==============================] - 0s 185us/step - loss: 0.3813 - acc: 0.9121 - val_loss: 0.4353 - val_acc: 0.8935\n",
      "Epoch 606/1000\n",
      "1649/1649 [==============================] - 0s 193us/step - loss: 0.3809 - acc: 0.9096 - val_loss: 0.4349 - val_acc: 0.8935\n",
      "Epoch 607/1000\n",
      "1649/1649 [==============================] - 0s 187us/step - loss: 0.3801 - acc: 0.9109 - val_loss: 0.4347 - val_acc: 0.8935\n",
      "Epoch 608/1000\n",
      "1649/1649 [==============================] - 0s 175us/step - loss: 0.3798 - acc: 0.9133 - val_loss: 0.4333 - val_acc: 0.8935\n",
      "Epoch 609/1000\n",
      "1649/1649 [==============================] - 0s 175us/step - loss: 0.3797 - acc: 0.9127 - val_loss: 0.4338 - val_acc: 0.8910\n",
      "Epoch 610/1000\n",
      "1649/1649 [==============================] - 0s 176us/step - loss: 0.3795 - acc: 0.9121 - val_loss: 0.4336 - val_acc: 0.8910\n",
      "Epoch 611/1000\n",
      "1649/1649 [==============================] - 0s 186us/step - loss: 0.3797 - acc: 0.9157 - val_loss: 0.4341 - val_acc: 0.8910\n",
      "Epoch 612/1000\n",
      "1649/1649 [==============================] - 0s 192us/step - loss: 0.3789 - acc: 0.9102 - val_loss: 0.4333 - val_acc: 0.8935\n",
      "Epoch 613/1000\n",
      "1649/1649 [==============================] - 0s 183us/step - loss: 0.3784 - acc: 0.9102 - val_loss: 0.4337 - val_acc: 0.8910\n",
      "Epoch 614/1000\n",
      "1649/1649 [==============================] - 0s 189us/step - loss: 0.3789 - acc: 0.9066 - val_loss: 0.4321 - val_acc: 0.8935\n",
      "Epoch 615/1000\n",
      "1649/1649 [==============================] - 0s 196us/step - loss: 0.3783 - acc: 0.9127 - val_loss: 0.4331 - val_acc: 0.8935\n",
      "Epoch 616/1000\n",
      "1649/1649 [==============================] - 0s 196us/step - loss: 0.3774 - acc: 0.9139 - val_loss: 0.4324 - val_acc: 0.8935\n",
      "Epoch 617/1000\n",
      "1649/1649 [==============================] - 0s 174us/step - loss: 0.3773 - acc: 0.9127 - val_loss: 0.4310 - val_acc: 0.8935\n",
      "Epoch 618/1000\n",
      "1649/1649 [==============================] - 0s 209us/step - loss: 0.3769 - acc: 0.9121 - val_loss: 0.4322 - val_acc: 0.8910\n",
      "Epoch 619/1000\n",
      "1649/1649 [==============================] - 0s 176us/step - loss: 0.3771 - acc: 0.9121 - val_loss: 0.4305 - val_acc: 0.8959\n",
      "Epoch 620/1000\n",
      "1649/1649 [==============================] - 0s 187us/step - loss: 0.3765 - acc: 0.9102 - val_loss: 0.4299 - val_acc: 0.8935\n",
      "Epoch 621/1000\n",
      "1649/1649 [==============================] - 0s 192us/step - loss: 0.3759 - acc: 0.9133 - val_loss: 0.4297 - val_acc: 0.8935\n",
      "Epoch 622/1000\n",
      "1649/1649 [==============================] - 0s 204us/step - loss: 0.3758 - acc: 0.9133 - val_loss: 0.4285 - val_acc: 0.8935\n",
      "Epoch 623/1000\n",
      "1649/1649 [==============================] - 0s 175us/step - loss: 0.3754 - acc: 0.9139 - val_loss: 0.4304 - val_acc: 0.8935\n",
      "Epoch 624/1000\n",
      "1649/1649 [==============================] - 0s 217us/step - loss: 0.3756 - acc: 0.9133 - val_loss: 0.4287 - val_acc: 0.8935\n",
      "Epoch 625/1000\n",
      "1649/1649 [==============================] - 0s 272us/step - loss: 0.3756 - acc: 0.9139 - val_loss: 0.4297 - val_acc: 0.8935\n",
      "Epoch 626/1000\n",
      "1649/1649 [==============================] - 0s 244us/step - loss: 0.3752 - acc: 0.9115 - val_loss: 0.4282 - val_acc: 0.8959\n",
      "Epoch 627/1000\n",
      "1649/1649 [==============================] - 0s 272us/step - loss: 0.3745 - acc: 0.9115 - val_loss: 0.4289 - val_acc: 0.8959\n",
      "Epoch 628/1000\n",
      "1649/1649 [==============================] - 0s 221us/step - loss: 0.3742 - acc: 0.9151 - val_loss: 0.4282 - val_acc: 0.8935\n",
      "Epoch 629/1000\n",
      "1649/1649 [==============================] - 0s 229us/step - loss: 0.3740 - acc: 0.9139 - val_loss: 0.4288 - val_acc: 0.8935\n",
      "Epoch 630/1000\n",
      "1649/1649 [==============================] - 0s 217us/step - loss: 0.3739 - acc: 0.9115 - val_loss: 0.4278 - val_acc: 0.8959\n",
      "Epoch 631/1000\n",
      "1649/1649 [==============================] - 0s 186us/step - loss: 0.3733 - acc: 0.9127 - val_loss: 0.4275 - val_acc: 0.8959\n",
      "Epoch 632/1000\n",
      "1649/1649 [==============================] - 0s 202us/step - loss: 0.3734 - acc: 0.9151 - val_loss: 0.4296 - val_acc: 0.8935\n",
      "Epoch 633/1000\n",
      "1649/1649 [==============================] - 0s 210us/step - loss: 0.3731 - acc: 0.9102 - val_loss: 0.4271 - val_acc: 0.8935\n",
      "Epoch 634/1000\n",
      "1649/1649 [==============================] - 0s 192us/step - loss: 0.3727 - acc: 0.9127 - val_loss: 0.4269 - val_acc: 0.8935\n",
      "Epoch 635/1000\n",
      "1649/1649 [==============================] - 0s 197us/step - loss: 0.3720 - acc: 0.9102 - val_loss: 0.4260 - val_acc: 0.8935\n",
      "Epoch 636/1000\n",
      "1649/1649 [==============================] - 0s 205us/step - loss: 0.3720 - acc: 0.9139 - val_loss: 0.4274 - val_acc: 0.8959\n",
      "Epoch 637/1000\n",
      "1649/1649 [==============================] - 0s 194us/step - loss: 0.3724 - acc: 0.9127 - val_loss: 0.4281 - val_acc: 0.8935\n",
      "Epoch 638/1000\n",
      "1649/1649 [==============================] - 0s 190us/step - loss: 0.3714 - acc: 0.9157 - val_loss: 0.4256 - val_acc: 0.8935\n",
      "Epoch 639/1000\n",
      "1649/1649 [==============================] - 0s 175us/step - loss: 0.3716 - acc: 0.9175 - val_loss: 0.4247 - val_acc: 0.8935\n",
      "Epoch 640/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1649/1649 [==============================] - 0s 175us/step - loss: 0.3712 - acc: 0.9145 - val_loss: 0.4252 - val_acc: 0.8959\n",
      "Epoch 641/1000\n",
      "1649/1649 [==============================] - 0s 176us/step - loss: 0.3706 - acc: 0.9121 - val_loss: 0.4266 - val_acc: 0.8935\n",
      "Epoch 642/1000\n",
      "1649/1649 [==============================] - 0s 172us/step - loss: 0.3711 - acc: 0.9127 - val_loss: 0.4256 - val_acc: 0.8959\n",
      "Epoch 643/1000\n",
      "1649/1649 [==============================] - 0s 173us/step - loss: 0.3701 - acc: 0.9145 - val_loss: 0.4238 - val_acc: 0.8935\n",
      "Epoch 644/1000\n",
      "1649/1649 [==============================] - 0s 172us/step - loss: 0.3697 - acc: 0.9121 - val_loss: 0.4243 - val_acc: 0.8935\n",
      "Epoch 645/1000\n",
      "1649/1649 [==============================] - 0s 165us/step - loss: 0.3694 - acc: 0.9145 - val_loss: 0.4245 - val_acc: 0.8910\n",
      "Epoch 646/1000\n",
      "1649/1649 [==============================] - 0s 190us/step - loss: 0.3695 - acc: 0.9151 - val_loss: 0.4239 - val_acc: 0.8959\n",
      "Epoch 647/1000\n",
      "1649/1649 [==============================] - 0s 197us/step - loss: 0.3694 - acc: 0.9115 - val_loss: 0.4261 - val_acc: 0.8935\n",
      "Epoch 648/1000\n",
      "1649/1649 [==============================] - 0s 169us/step - loss: 0.3690 - acc: 0.9151 - val_loss: 0.4229 - val_acc: 0.8959\n",
      "Epoch 649/1000\n",
      "1649/1649 [==============================] - 0s 175us/step - loss: 0.3685 - acc: 0.9127 - val_loss: 0.4238 - val_acc: 0.8959\n",
      "Epoch 650/1000\n",
      "1649/1649 [==============================] - 0s 193us/step - loss: 0.3685 - acc: 0.9151 - val_loss: 0.4229 - val_acc: 0.8959\n",
      "Epoch 651/1000\n",
      "1649/1649 [==============================] - 0s 173us/step - loss: 0.3680 - acc: 0.9139 - val_loss: 0.4230 - val_acc: 0.8959\n",
      "Epoch 652/1000\n",
      "1649/1649 [==============================] - 0s 178us/step - loss: 0.3678 - acc: 0.9157 - val_loss: 0.4217 - val_acc: 0.8935\n",
      "Epoch 653/1000\n",
      "1649/1649 [==============================] - 0s 201us/step - loss: 0.3676 - acc: 0.9151 - val_loss: 0.4218 - val_acc: 0.8935\n",
      "Epoch 654/1000\n",
      "1649/1649 [==============================] - 0s 179us/step - loss: 0.3671 - acc: 0.9151 - val_loss: 0.4223 - val_acc: 0.8935\n",
      "Epoch 655/1000\n",
      "1649/1649 [==============================] - 0s 178us/step - loss: 0.3668 - acc: 0.9139 - val_loss: 0.4208 - val_acc: 0.8935\n",
      "Epoch 656/1000\n",
      "1649/1649 [==============================] - 0s 171us/step - loss: 0.3664 - acc: 0.9145 - val_loss: 0.4222 - val_acc: 0.8959\n",
      "Epoch 657/1000\n",
      "1649/1649 [==============================] - 0s 193us/step - loss: 0.3663 - acc: 0.9151 - val_loss: 0.4225 - val_acc: 0.8910\n",
      "Epoch 658/1000\n",
      "1649/1649 [==============================] - 0s 169us/step - loss: 0.3661 - acc: 0.9139 - val_loss: 0.4207 - val_acc: 0.8959\n",
      "Epoch 659/1000\n",
      "1649/1649 [==============================] - 0s 170us/step - loss: 0.3659 - acc: 0.9145 - val_loss: 0.4204 - val_acc: 0.8935\n",
      "Epoch 660/1000\n",
      "1649/1649 [==============================] - 0s 196us/step - loss: 0.3657 - acc: 0.9169 - val_loss: 0.4210 - val_acc: 0.8935\n",
      "Epoch 661/1000\n",
      "1649/1649 [==============================] - 0s 189us/step - loss: 0.3654 - acc: 0.9157 - val_loss: 0.4211 - val_acc: 0.8935\n",
      "Epoch 662/1000\n",
      "1649/1649 [==============================] - 0s 182us/step - loss: 0.3654 - acc: 0.9139 - val_loss: 0.4199 - val_acc: 0.8935\n",
      "Epoch 663/1000\n",
      "1649/1649 [==============================] - 0s 190us/step - loss: 0.3651 - acc: 0.9169 - val_loss: 0.4204 - val_acc: 0.8935\n",
      "Epoch 664/1000\n",
      "1649/1649 [==============================] - 0s 185us/step - loss: 0.3646 - acc: 0.9145 - val_loss: 0.4200 - val_acc: 0.8959\n",
      "Epoch 665/1000\n",
      "1649/1649 [==============================] - 0s 201us/step - loss: 0.3646 - acc: 0.9157 - val_loss: 0.4200 - val_acc: 0.8983\n",
      "Epoch 666/1000\n",
      "1649/1649 [==============================] - 0s 236us/step - loss: 0.3639 - acc: 0.9163 - val_loss: 0.4192 - val_acc: 0.8935\n",
      "Epoch 667/1000\n",
      "1649/1649 [==============================] - 0s 197us/step - loss: 0.3639 - acc: 0.9157 - val_loss: 0.4189 - val_acc: 0.8959\n",
      "Epoch 668/1000\n",
      "1649/1649 [==============================] - 0s 224us/step - loss: 0.3635 - acc: 0.9151 - val_loss: 0.4174 - val_acc: 0.8959\n",
      "Epoch 669/1000\n",
      "1649/1649 [==============================] - 0s 206us/step - loss: 0.3634 - acc: 0.9139 - val_loss: 0.4199 - val_acc: 0.8935\n",
      "Epoch 670/1000\n",
      "1649/1649 [==============================] - 0s 186us/step - loss: 0.3631 - acc: 0.9175 - val_loss: 0.4182 - val_acc: 0.8935\n",
      "Epoch 671/1000\n",
      "1649/1649 [==============================] - 0s 216us/step - loss: 0.3629 - acc: 0.9157 - val_loss: 0.4196 - val_acc: 0.8935\n",
      "Epoch 672/1000\n",
      "1649/1649 [==============================] - 0s 194us/step - loss: 0.3627 - acc: 0.9127 - val_loss: 0.4177 - val_acc: 0.8935\n",
      "Epoch 673/1000\n",
      "1649/1649 [==============================] - 0s 202us/step - loss: 0.3625 - acc: 0.9121 - val_loss: 0.4170 - val_acc: 0.8935\n",
      "Epoch 674/1000\n",
      "1649/1649 [==============================] - 0s 230us/step - loss: 0.3624 - acc: 0.9145 - val_loss: 0.4169 - val_acc: 0.8959\n",
      "Epoch 675/1000\n",
      "1649/1649 [==============================] - 0s 249us/step - loss: 0.3618 - acc: 0.9163 - val_loss: 0.4172 - val_acc: 0.8935\n",
      "Epoch 676/1000\n",
      "1649/1649 [==============================] - 0s 280us/step - loss: 0.3626 - acc: 0.9145 - val_loss: 0.4183 - val_acc: 0.8935\n",
      "Epoch 677/1000\n",
      "1649/1649 [==============================] - 0s 193us/step - loss: 0.3615 - acc: 0.9181 - val_loss: 0.4174 - val_acc: 0.8935\n",
      "Epoch 678/1000\n",
      "1649/1649 [==============================] - 0s 264us/step - loss: 0.3611 - acc: 0.9181 - val_loss: 0.4161 - val_acc: 0.8935\n",
      "Epoch 679/1000\n",
      "1649/1649 [==============================] - 0s 241us/step - loss: 0.3610 - acc: 0.9157 - val_loss: 0.4162 - val_acc: 0.8935\n",
      "Epoch 680/1000\n",
      "1649/1649 [==============================] - 0s 187us/step - loss: 0.3607 - acc: 0.9169 - val_loss: 0.4165 - val_acc: 0.8959\n",
      "Epoch 681/1000\n",
      "1649/1649 [==============================] - 0s 203us/step - loss: 0.3608 - acc: 0.9169 - val_loss: 0.4167 - val_acc: 0.8959\n",
      "Epoch 682/1000\n",
      "1649/1649 [==============================] - 0s 193us/step - loss: 0.3602 - acc: 0.9157 - val_loss: 0.4160 - val_acc: 0.8983\n",
      "Epoch 683/1000\n",
      "1649/1649 [==============================] - 0s 180us/step - loss: 0.3600 - acc: 0.9169 - val_loss: 0.4160 - val_acc: 0.8959\n",
      "Epoch 684/1000\n",
      "1649/1649 [==============================] - 0s 173us/step - loss: 0.3597 - acc: 0.9145 - val_loss: 0.4151 - val_acc: 0.8959\n",
      "Epoch 685/1000\n",
      "1649/1649 [==============================] - 0s 192us/step - loss: 0.3591 - acc: 0.9175 - val_loss: 0.4152 - val_acc: 0.8935\n",
      "Epoch 686/1000\n",
      "1649/1649 [==============================] - 0s 202us/step - loss: 0.3595 - acc: 0.9181 - val_loss: 0.4137 - val_acc: 0.8935\n",
      "Epoch 687/1000\n",
      "1649/1649 [==============================] - 0s 210us/step - loss: 0.3589 - acc: 0.9163 - val_loss: 0.4145 - val_acc: 0.8983\n",
      "Epoch 688/1000\n",
      "1649/1649 [==============================] - 0s 196us/step - loss: 0.3591 - acc: 0.9187 - val_loss: 0.4134 - val_acc: 0.8959\n",
      "Epoch 689/1000\n",
      "1649/1649 [==============================] - 0s 212us/step - loss: 0.3586 - acc: 0.9187 - val_loss: 0.4138 - val_acc: 0.8959\n",
      "Epoch 690/1000\n",
      "1649/1649 [==============================] - 0s 224us/step - loss: 0.3581 - acc: 0.9157 - val_loss: 0.4140 - val_acc: 0.8959\n",
      "Epoch 691/1000\n",
      "1649/1649 [==============================] - 0s 261us/step - loss: 0.3579 - acc: 0.9163 - val_loss: 0.4132 - val_acc: 0.8935\n",
      "Epoch 692/1000\n",
      "1649/1649 [==============================] - 0s 270us/step - loss: 0.3580 - acc: 0.9175 - val_loss: 0.4118 - val_acc: 0.8935\n",
      "Epoch 693/1000\n",
      "1649/1649 [==============================] - 0s 232us/step - loss: 0.3575 - acc: 0.9175 - val_loss: 0.4126 - val_acc: 0.8935\n",
      "Epoch 694/1000\n",
      "1649/1649 [==============================] - 0s 230us/step - loss: 0.3570 - acc: 0.9169 - val_loss: 0.4122 - val_acc: 0.8935\n",
      "Epoch 695/1000\n",
      "1649/1649 [==============================] - 0s 212us/step - loss: 0.3570 - acc: 0.9157 - val_loss: 0.4130 - val_acc: 0.8959\n",
      "Epoch 696/1000\n",
      "1649/1649 [==============================] - 0s 237us/step - loss: 0.3569 - acc: 0.9200 - val_loss: 0.4126 - val_acc: 0.8959\n",
      "Epoch 697/1000\n",
      "1649/1649 [==============================] - 0s 227us/step - loss: 0.3562 - acc: 0.9151 - val_loss: 0.4106 - val_acc: 0.8983\n",
      "Epoch 698/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1649/1649 [==============================] - 0s 223us/step - loss: 0.3563 - acc: 0.9181 - val_loss: 0.4114 - val_acc: 0.8935\n",
      "Epoch 699/1000\n",
      "1649/1649 [==============================] - 0s 195us/step - loss: 0.3562 - acc: 0.9200 - val_loss: 0.4116 - val_acc: 0.8959\n",
      "Epoch 700/1000\n",
      "1649/1649 [==============================] - 0s 196us/step - loss: 0.3564 - acc: 0.9181 - val_loss: 0.4098 - val_acc: 0.8959\n",
      "Epoch 701/1000\n",
      "1649/1649 [==============================] - 0s 208us/step - loss: 0.3553 - acc: 0.9193 - val_loss: 0.4115 - val_acc: 0.8959\n",
      "Epoch 702/1000\n",
      "1649/1649 [==============================] - 0s 180us/step - loss: 0.3551 - acc: 0.9175 - val_loss: 0.4097 - val_acc: 0.8959\n",
      "Epoch 703/1000\n",
      "1649/1649 [==============================] - 0s 203us/step - loss: 0.3551 - acc: 0.9187 - val_loss: 0.4105 - val_acc: 0.8959\n",
      "Epoch 704/1000\n",
      "1649/1649 [==============================] - 0s 198us/step - loss: 0.3549 - acc: 0.9169 - val_loss: 0.4115 - val_acc: 0.8959\n",
      "Epoch 705/1000\n",
      "1649/1649 [==============================] - 0s 212us/step - loss: 0.3547 - acc: 0.9200 - val_loss: 0.4098 - val_acc: 0.8983\n",
      "Epoch 706/1000\n",
      "1649/1649 [==============================] - 0s 178us/step - loss: 0.3547 - acc: 0.9187 - val_loss: 0.4108 - val_acc: 0.8959\n",
      "Epoch 707/1000\n",
      "1649/1649 [==============================] - 0s 206us/step - loss: 0.3546 - acc: 0.9181 - val_loss: 0.4086 - val_acc: 0.8935\n",
      "Epoch 708/1000\n",
      "1649/1649 [==============================] - 0s 200us/step - loss: 0.3534 - acc: 0.9187 - val_loss: 0.4108 - val_acc: 0.8959\n",
      "Epoch 709/1000\n",
      "1649/1649 [==============================] - 0s 195us/step - loss: 0.3538 - acc: 0.9175 - val_loss: 0.4098 - val_acc: 0.8959\n",
      "Epoch 710/1000\n",
      "1649/1649 [==============================] - 0s 204us/step - loss: 0.3532 - acc: 0.9151 - val_loss: 0.4103 - val_acc: 0.8959\n",
      "Epoch 711/1000\n",
      "1649/1649 [==============================] - 0s 200us/step - loss: 0.3530 - acc: 0.9187 - val_loss: 0.4089 - val_acc: 0.8959\n",
      "Epoch 712/1000\n",
      "1649/1649 [==============================] - 0s 200us/step - loss: 0.3532 - acc: 0.9151 - val_loss: 0.4103 - val_acc: 0.8935\n",
      "Epoch 713/1000\n",
      "1649/1649 [==============================] - 0s 205us/step - loss: 0.3527 - acc: 0.9175 - val_loss: 0.4081 - val_acc: 0.8959\n",
      "Epoch 714/1000\n",
      "1649/1649 [==============================] - 0s 198us/step - loss: 0.3524 - acc: 0.9175 - val_loss: 0.4082 - val_acc: 0.8959\n",
      "Epoch 715/1000\n",
      "1649/1649 [==============================] - 0s 197us/step - loss: 0.3521 - acc: 0.9187 - val_loss: 0.4070 - val_acc: 0.8935\n",
      "Epoch 716/1000\n",
      "1649/1649 [==============================] - 0s 187us/step - loss: 0.3521 - acc: 0.9200 - val_loss: 0.4093 - val_acc: 0.8959\n",
      "Epoch 717/1000\n",
      "1649/1649 [==============================] - 0s 173us/step - loss: 0.3517 - acc: 0.9175 - val_loss: 0.4075 - val_acc: 0.8959\n",
      "Epoch 718/1000\n",
      "1649/1649 [==============================] - 0s 187us/step - loss: 0.3514 - acc: 0.9187 - val_loss: 0.4072 - val_acc: 0.8959\n",
      "Epoch 719/1000\n",
      "1649/1649 [==============================] - 0s 198us/step - loss: 0.3513 - acc: 0.9187 - val_loss: 0.4071 - val_acc: 0.8959\n",
      "Epoch 720/1000\n",
      "1649/1649 [==============================] - 0s 238us/step - loss: 0.3511 - acc: 0.9200 - val_loss: 0.4065 - val_acc: 0.8959\n",
      "Epoch 721/1000\n",
      "1649/1649 [==============================] - 0s 237us/step - loss: 0.3508 - acc: 0.9200 - val_loss: 0.4074 - val_acc: 0.8959\n",
      "Epoch 722/1000\n",
      "1649/1649 [==============================] - 0s 273us/step - loss: 0.3513 - acc: 0.9163 - val_loss: 0.4056 - val_acc: 0.8983\n",
      "Epoch 723/1000\n",
      "1649/1649 [==============================] - 0s 199us/step - loss: 0.3505 - acc: 0.9200 - val_loss: 0.4073 - val_acc: 0.8959\n",
      "Epoch 724/1000\n",
      "1649/1649 [==============================] - 0s 259us/step - loss: 0.3505 - acc: 0.9181 - val_loss: 0.4052 - val_acc: 0.8935\n",
      "Epoch 725/1000\n",
      "1649/1649 [==============================] - 0s 276us/step - loss: 0.3499 - acc: 0.9212 - val_loss: 0.4063 - val_acc: 0.8959\n",
      "Epoch 726/1000\n",
      "1649/1649 [==============================] - 0s 204us/step - loss: 0.3496 - acc: 0.9206 - val_loss: 0.4065 - val_acc: 0.8959\n",
      "Epoch 727/1000\n",
      "1649/1649 [==============================] - 0s 218us/step - loss: 0.3499 - acc: 0.9175 - val_loss: 0.4069 - val_acc: 0.8959\n",
      "Epoch 728/1000\n",
      "1649/1649 [==============================] - 0s 209us/step - loss: 0.3495 - acc: 0.9193 - val_loss: 0.4055 - val_acc: 0.8959\n",
      "Epoch 729/1000\n",
      "1649/1649 [==============================] - 0s 201us/step - loss: 0.3495 - acc: 0.9193 - val_loss: 0.4068 - val_acc: 0.8959\n",
      "Epoch 730/1000\n",
      "1649/1649 [==============================] - 0s 225us/step - loss: 0.3491 - acc: 0.9212 - val_loss: 0.4058 - val_acc: 0.8959\n",
      "Epoch 731/1000\n",
      "1649/1649 [==============================] - 0s 228us/step - loss: 0.3486 - acc: 0.9206 - val_loss: 0.4044 - val_acc: 0.8959\n",
      "Epoch 732/1000\n",
      "1649/1649 [==============================] - 0s 199us/step - loss: 0.3483 - acc: 0.9181 - val_loss: 0.4043 - val_acc: 0.8959\n",
      "Epoch 733/1000\n",
      "1649/1649 [==============================] - 0s 246us/step - loss: 0.3479 - acc: 0.9200 - val_loss: 0.4041 - val_acc: 0.8959\n",
      "Epoch 734/1000\n",
      "1649/1649 [==============================] - 0s 205us/step - loss: 0.3483 - acc: 0.9181 - val_loss: 0.4033 - val_acc: 0.8959\n",
      "Epoch 735/1000\n",
      "1649/1649 [==============================] - 0s 237us/step - loss: 0.3480 - acc: 0.9187 - val_loss: 0.4038 - val_acc: 0.8959\n",
      "Epoch 736/1000\n",
      "1649/1649 [==============================] - 0s 229us/step - loss: 0.3473 - acc: 0.9218 - val_loss: 0.4044 - val_acc: 0.8959\n",
      "Epoch 737/1000\n",
      "1649/1649 [==============================] - 0s 220us/step - loss: 0.3469 - acc: 0.9193 - val_loss: 0.4031 - val_acc: 0.8983\n",
      "Epoch 738/1000\n",
      "1649/1649 [==============================] - 0s 223us/step - loss: 0.3471 - acc: 0.9175 - val_loss: 0.4030 - val_acc: 0.8983\n",
      "Epoch 739/1000\n",
      "1649/1649 [==============================] - 0s 204us/step - loss: 0.3469 - acc: 0.9200 - val_loss: 0.4042 - val_acc: 0.8959\n",
      "Epoch 740/1000\n",
      "1649/1649 [==============================] - 0s 221us/step - loss: 0.3468 - acc: 0.9175 - val_loss: 0.4021 - val_acc: 0.8983\n",
      "Epoch 741/1000\n",
      "1649/1649 [==============================] - 0s 233us/step - loss: 0.3465 - acc: 0.9200 - val_loss: 0.4034 - val_acc: 0.8959\n",
      "Epoch 742/1000\n",
      "1649/1649 [==============================] - 0s 241us/step - loss: 0.3466 - acc: 0.9193 - val_loss: 0.4011 - val_acc: 0.9007\n",
      "Epoch 743/1000\n",
      "1649/1649 [==============================] - 0s 204us/step - loss: 0.3459 - acc: 0.9212 - val_loss: 0.4024 - val_acc: 0.8935\n",
      "Epoch 744/1000\n",
      "1649/1649 [==============================] - 0s 239us/step - loss: 0.3457 - acc: 0.9206 - val_loss: 0.4017 - val_acc: 0.8959\n",
      "Epoch 745/1000\n",
      "1649/1649 [==============================] - 0s 207us/step - loss: 0.3454 - acc: 0.9224 - val_loss: 0.4029 - val_acc: 0.8959\n",
      "Epoch 746/1000\n",
      "1649/1649 [==============================] - 0s 238us/step - loss: 0.3451 - acc: 0.9218 - val_loss: 0.4010 - val_acc: 0.8959\n",
      "Epoch 747/1000\n",
      "1649/1649 [==============================] - 0s 233us/step - loss: 0.3450 - acc: 0.9206 - val_loss: 0.4010 - val_acc: 0.8959\n",
      "Epoch 748/1000\n",
      "1649/1649 [==============================] - 0s 236us/step - loss: 0.3451 - acc: 0.9200 - val_loss: 0.4022 - val_acc: 0.8959\n",
      "Epoch 749/1000\n",
      "1649/1649 [==============================] - 0s 251us/step - loss: 0.3447 - acc: 0.9206 - val_loss: 0.4007 - val_acc: 0.8959\n",
      "Epoch 750/1000\n",
      "1649/1649 [==============================] - 0s 231us/step - loss: 0.3446 - acc: 0.9200 - val_loss: 0.3994 - val_acc: 0.8983\n",
      "Epoch 751/1000\n",
      "1649/1649 [==============================] - 0s 216us/step - loss: 0.3442 - acc: 0.9206 - val_loss: 0.4011 - val_acc: 0.8959\n",
      "Epoch 752/1000\n",
      "1649/1649 [==============================] - 0s 227us/step - loss: 0.3439 - acc: 0.9200 - val_loss: 0.3996 - val_acc: 0.8983\n",
      "Epoch 753/1000\n",
      "1649/1649 [==============================] - 0s 210us/step - loss: 0.3438 - acc: 0.9218 - val_loss: 0.3993 - val_acc: 0.8983\n",
      "Epoch 754/1000\n",
      "1649/1649 [==============================] - 0s 232us/step - loss: 0.3433 - acc: 0.9200 - val_loss: 0.4000 - val_acc: 0.8959\n",
      "Epoch 755/1000\n",
      "1649/1649 [==============================] - 0s 224us/step - loss: 0.3434 - acc: 0.9212 - val_loss: 0.3994 - val_acc: 0.8983\n",
      "Epoch 756/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1649/1649 [==============================] - 0s 194us/step - loss: 0.3431 - acc: 0.9212 - val_loss: 0.4005 - val_acc: 0.8959\n",
      "Epoch 757/1000\n",
      "1649/1649 [==============================] - 0s 184us/step - loss: 0.3430 - acc: 0.9224 - val_loss: 0.3985 - val_acc: 0.9007\n",
      "Epoch 758/1000\n",
      "1649/1649 [==============================] - 0s 211us/step - loss: 0.3427 - acc: 0.9206 - val_loss: 0.3981 - val_acc: 0.9007\n",
      "Epoch 759/1000\n",
      "1649/1649 [==============================] - 0s 198us/step - loss: 0.3425 - acc: 0.9206 - val_loss: 0.3996 - val_acc: 0.8959\n",
      "Epoch 760/1000\n",
      "1649/1649 [==============================] - 0s 198us/step - loss: 0.3426 - acc: 0.9200 - val_loss: 0.3982 - val_acc: 0.8983\n",
      "Epoch 761/1000\n",
      "1649/1649 [==============================] - 0s 193us/step - loss: 0.3421 - acc: 0.9212 - val_loss: 0.3987 - val_acc: 0.8959\n",
      "Epoch 762/1000\n",
      "1649/1649 [==============================] - 0s 192us/step - loss: 0.3416 - acc: 0.9224 - val_loss: 0.3979 - val_acc: 0.8983\n",
      "Epoch 763/1000\n",
      "1649/1649 [==============================] - 0s 240us/step - loss: 0.3417 - acc: 0.9206 - val_loss: 0.3983 - val_acc: 0.8959\n",
      "Epoch 764/1000\n",
      "1649/1649 [==============================] - 0s 278us/step - loss: 0.3416 - acc: 0.9224 - val_loss: 0.3972 - val_acc: 0.8983\n",
      "Epoch 765/1000\n",
      "1649/1649 [==============================] - 0s 237us/step - loss: 0.3415 - acc: 0.9206 - val_loss: 0.3966 - val_acc: 0.8983\n",
      "Epoch 766/1000\n",
      "1649/1649 [==============================] - 0s 227us/step - loss: 0.3408 - acc: 0.9242 - val_loss: 0.3976 - val_acc: 0.8959\n",
      "Epoch 767/1000\n",
      "1649/1649 [==============================] - 0s 223us/step - loss: 0.3405 - acc: 0.9200 - val_loss: 0.3981 - val_acc: 0.8959\n",
      "Epoch 768/1000\n",
      "1649/1649 [==============================] - 0s 271us/step - loss: 0.3409 - acc: 0.9218 - val_loss: 0.3958 - val_acc: 0.9007\n",
      "Epoch 769/1000\n",
      "1649/1649 [==============================] - 0s 215us/step - loss: 0.3407 - acc: 0.9218 - val_loss: 0.3970 - val_acc: 0.8959\n",
      "Epoch 770/1000\n",
      "1649/1649 [==============================] - 0s 206us/step - loss: 0.3400 - acc: 0.9236 - val_loss: 0.3972 - val_acc: 0.8959\n",
      "Epoch 771/1000\n",
      "1649/1649 [==============================] - 0s 220us/step - loss: 0.3401 - acc: 0.9193 - val_loss: 0.3976 - val_acc: 0.8959\n",
      "Epoch 772/1000\n",
      "1649/1649 [==============================] - 0s 210us/step - loss: 0.3395 - acc: 0.9242 - val_loss: 0.3962 - val_acc: 0.8983\n",
      "Epoch 773/1000\n",
      "1649/1649 [==============================] - 0s 202us/step - loss: 0.3392 - acc: 0.9230 - val_loss: 0.3963 - val_acc: 0.8959\n",
      "Epoch 774/1000\n",
      "1649/1649 [==============================] - 0s 207us/step - loss: 0.3392 - acc: 0.9230 - val_loss: 0.3974 - val_acc: 0.8959\n",
      "Epoch 775/1000\n",
      "1649/1649 [==============================] - 0s 198us/step - loss: 0.3390 - acc: 0.9212 - val_loss: 0.3969 - val_acc: 0.8983\n",
      "Epoch 776/1000\n",
      "1649/1649 [==============================] - 0s 210us/step - loss: 0.3397 - acc: 0.9193 - val_loss: 0.3956 - val_acc: 0.8959\n",
      "Epoch 777/1000\n",
      "1649/1649 [==============================] - 0s 224us/step - loss: 0.3388 - acc: 0.9242 - val_loss: 0.3963 - val_acc: 0.8959\n",
      "Epoch 778/1000\n",
      "1649/1649 [==============================] - 0s 197us/step - loss: 0.3384 - acc: 0.9260 - val_loss: 0.3954 - val_acc: 0.8983\n",
      "Epoch 779/1000\n",
      "1649/1649 [==============================] - 0s 177us/step - loss: 0.3381 - acc: 0.9224 - val_loss: 0.3954 - val_acc: 0.8959\n",
      "Epoch 780/1000\n",
      "1649/1649 [==============================] - 0s 190us/step - loss: 0.3379 - acc: 0.9224 - val_loss: 0.3944 - val_acc: 0.8983\n",
      "Epoch 781/1000\n",
      "1649/1649 [==============================] - 0s 204us/step - loss: 0.3375 - acc: 0.9224 - val_loss: 0.3957 - val_acc: 0.8959\n",
      "Epoch 782/1000\n",
      "1649/1649 [==============================] - 0s 210us/step - loss: 0.3376 - acc: 0.9236 - val_loss: 0.3946 - val_acc: 0.8983\n",
      "Epoch 783/1000\n",
      "1649/1649 [==============================] - 0s 233us/step - loss: 0.3372 - acc: 0.9224 - val_loss: 0.3933 - val_acc: 0.9007\n",
      "Epoch 784/1000\n",
      "1649/1649 [==============================] - 0s 209us/step - loss: 0.3370 - acc: 0.9218 - val_loss: 0.3953 - val_acc: 0.8959\n",
      "Epoch 785/1000\n",
      "1649/1649 [==============================] - 0s 227us/step - loss: 0.3368 - acc: 0.9242 - val_loss: 0.3938 - val_acc: 0.8983\n",
      "Epoch 786/1000\n",
      "1649/1649 [==============================] - 0s 231us/step - loss: 0.3371 - acc: 0.9230 - val_loss: 0.3942 - val_acc: 0.8959\n",
      "Epoch 787/1000\n",
      "1649/1649 [==============================] - 0s 233us/step - loss: 0.3365 - acc: 0.9236 - val_loss: 0.3929 - val_acc: 0.8983\n",
      "Epoch 788/1000\n",
      "1649/1649 [==============================] - 0s 238us/step - loss: 0.3375 - acc: 0.9236 - val_loss: 0.3932 - val_acc: 0.9007\n",
      "Epoch 789/1000\n",
      "1649/1649 [==============================] - 0s 240us/step - loss: 0.3362 - acc: 0.9218 - val_loss: 0.3945 - val_acc: 0.8983\n",
      "Epoch 790/1000\n",
      "1649/1649 [==============================] - 0s 229us/step - loss: 0.3359 - acc: 0.9212 - val_loss: 0.3933 - val_acc: 0.8959\n",
      "Epoch 791/1000\n",
      "1649/1649 [==============================] - 0s 208us/step - loss: 0.3361 - acc: 0.9236 - val_loss: 0.3928 - val_acc: 0.8959\n",
      "Epoch 792/1000\n",
      "1649/1649 [==============================] - 0s 241us/step - loss: 0.3357 - acc: 0.9236 - val_loss: 0.3926 - val_acc: 0.8959\n",
      "Epoch 793/1000\n",
      "1649/1649 [==============================] - 0s 243us/step - loss: 0.3361 - acc: 0.9260 - val_loss: 0.3940 - val_acc: 0.8983\n",
      "Epoch 794/1000\n",
      "1649/1649 [==============================] - 0s 261us/step - loss: 0.3356 - acc: 0.9242 - val_loss: 0.3916 - val_acc: 0.9007\n",
      "Epoch 795/1000\n",
      "1649/1649 [==============================] - 0s 286us/step - loss: 0.3350 - acc: 0.9236 - val_loss: 0.3916 - val_acc: 0.9007\n",
      "Epoch 796/1000\n",
      "1649/1649 [==============================] - 0s 203us/step - loss: 0.3349 - acc: 0.9236 - val_loss: 0.3919 - val_acc: 0.8959\n",
      "Epoch 797/1000\n",
      "1649/1649 [==============================] - 0s 223us/step - loss: 0.3346 - acc: 0.9236 - val_loss: 0.3924 - val_acc: 0.8983\n",
      "Epoch 798/1000\n",
      "1649/1649 [==============================] - 0s 226us/step - loss: 0.3348 - acc: 0.9242 - val_loss: 0.3924 - val_acc: 0.8959\n",
      "Epoch 799/1000\n",
      "1649/1649 [==============================] - 0s 223us/step - loss: 0.3348 - acc: 0.9236 - val_loss: 0.3921 - val_acc: 0.8959\n",
      "Epoch 800/1000\n",
      "1649/1649 [==============================] - 0s 206us/step - loss: 0.3342 - acc: 0.9260 - val_loss: 0.3925 - val_acc: 0.8935\n",
      "Epoch 801/1000\n",
      "1649/1649 [==============================] - 0s 233us/step - loss: 0.3336 - acc: 0.9242 - val_loss: 0.3909 - val_acc: 0.8959\n",
      "Epoch 802/1000\n",
      "1649/1649 [==============================] - 0s 216us/step - loss: 0.3339 - acc: 0.9248 - val_loss: 0.3896 - val_acc: 0.9007\n",
      "Epoch 803/1000\n",
      "1649/1649 [==============================] - 0s 240us/step - loss: 0.3333 - acc: 0.9254 - val_loss: 0.3914 - val_acc: 0.8959\n",
      "Epoch 804/1000\n",
      "1649/1649 [==============================] - 0s 227us/step - loss: 0.3332 - acc: 0.9248 - val_loss: 0.3897 - val_acc: 0.9007\n",
      "Epoch 805/1000\n",
      "1649/1649 [==============================] - 0s 235us/step - loss: 0.3330 - acc: 0.9236 - val_loss: 0.3910 - val_acc: 0.8959\n",
      "Epoch 806/1000\n",
      "1649/1649 [==============================] - 0s 267us/step - loss: 0.3331 - acc: 0.9266 - val_loss: 0.3900 - val_acc: 0.8983\n",
      "Epoch 807/1000\n",
      "1649/1649 [==============================] - 1s 308us/step - loss: 0.3325 - acc: 0.9212 - val_loss: 0.3887 - val_acc: 0.9007\n",
      "Epoch 808/1000\n",
      "1649/1649 [==============================] - 1s 310us/step - loss: 0.3332 - acc: 0.9254 - val_loss: 0.3896 - val_acc: 0.9007\n",
      "Epoch 809/1000\n",
      "1649/1649 [==============================] - 0s 234us/step - loss: 0.3321 - acc: 0.9260 - val_loss: 0.3907 - val_acc: 0.8983\n",
      "Epoch 810/1000\n",
      "1649/1649 [==============================] - 0s 289us/step - loss: 0.3318 - acc: 0.9260 - val_loss: 0.3898 - val_acc: 0.8935\n",
      "Epoch 811/1000\n",
      "1649/1649 [==============================] - 0s 243us/step - loss: 0.3322 - acc: 0.9248 - val_loss: 0.3903 - val_acc: 0.8983\n",
      "Epoch 812/1000\n",
      "1649/1649 [==============================] - 0s 216us/step - loss: 0.3318 - acc: 0.9242 - val_loss: 0.3891 - val_acc: 0.8983\n",
      "Epoch 813/1000\n",
      "1649/1649 [==============================] - 0s 220us/step - loss: 0.3320 - acc: 0.9236 - val_loss: 0.3895 - val_acc: 0.8983\n",
      "Epoch 814/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1649/1649 [==============================] - 0s 205us/step - loss: 0.3312 - acc: 0.9266 - val_loss: 0.3897 - val_acc: 0.8959\n",
      "Epoch 815/1000\n",
      "1649/1649 [==============================] - 0s 199us/step - loss: 0.3314 - acc: 0.9260 - val_loss: 0.3891 - val_acc: 0.8983\n",
      "Epoch 816/1000\n",
      "1649/1649 [==============================] - 0s 199us/step - loss: 0.3307 - acc: 0.9260 - val_loss: 0.3880 - val_acc: 0.8983\n",
      "Epoch 817/1000\n",
      "1649/1649 [==============================] - 0s 190us/step - loss: 0.3306 - acc: 0.9254 - val_loss: 0.3883 - val_acc: 0.8983\n",
      "Epoch 818/1000\n",
      "1649/1649 [==============================] - 0s 192us/step - loss: 0.3303 - acc: 0.9254 - val_loss: 0.3885 - val_acc: 0.8983\n",
      "Epoch 819/1000\n",
      "1649/1649 [==============================] - 0s 199us/step - loss: 0.3305 - acc: 0.9242 - val_loss: 0.3871 - val_acc: 0.9007\n",
      "Epoch 820/1000\n",
      "1649/1649 [==============================] - 0s 190us/step - loss: 0.3303 - acc: 0.9284 - val_loss: 0.3879 - val_acc: 0.8983\n",
      "Epoch 821/1000\n",
      "1649/1649 [==============================] - 0s 210us/step - loss: 0.3300 - acc: 0.9260 - val_loss: 0.3882 - val_acc: 0.8959\n",
      "Epoch 822/1000\n",
      "1649/1649 [==============================] - 0s 191us/step - loss: 0.3298 - acc: 0.9230 - val_loss: 0.3880 - val_acc: 0.8983\n",
      "Epoch 823/1000\n",
      "1649/1649 [==============================] - 0s 195us/step - loss: 0.3294 - acc: 0.9260 - val_loss: 0.3870 - val_acc: 0.8983\n",
      "Epoch 824/1000\n",
      "1649/1649 [==============================] - 0s 191us/step - loss: 0.3299 - acc: 0.9266 - val_loss: 0.3863 - val_acc: 0.9007\n",
      "Epoch 825/1000\n",
      "1649/1649 [==============================] - 0s 192us/step - loss: 0.3292 - acc: 0.9272 - val_loss: 0.3872 - val_acc: 0.8959\n",
      "Epoch 826/1000\n",
      "1649/1649 [==============================] - 0s 184us/step - loss: 0.3293 - acc: 0.9206 - val_loss: 0.3857 - val_acc: 0.9007\n",
      "Epoch 827/1000\n",
      "1649/1649 [==============================] - 0s 173us/step - loss: 0.3286 - acc: 0.9254 - val_loss: 0.3861 - val_acc: 0.8983\n",
      "Epoch 828/1000\n",
      "1649/1649 [==============================] - 0s 192us/step - loss: 0.3289 - acc: 0.9260 - val_loss: 0.3858 - val_acc: 0.9007\n",
      "Epoch 829/1000\n",
      "1649/1649 [==============================] - 0s 180us/step - loss: 0.3283 - acc: 0.9260 - val_loss: 0.3853 - val_acc: 0.9007\n",
      "Epoch 830/1000\n",
      "1649/1649 [==============================] - 0s 181us/step - loss: 0.3282 - acc: 0.9260 - val_loss: 0.3852 - val_acc: 0.9007\n",
      "Epoch 831/1000\n",
      "1649/1649 [==============================] - 0s 190us/step - loss: 0.3286 - acc: 0.9254 - val_loss: 0.3860 - val_acc: 0.8983\n",
      "Epoch 832/1000\n",
      "1649/1649 [==============================] - 0s 206us/step - loss: 0.3275 - acc: 0.9284 - val_loss: 0.3850 - val_acc: 0.9007\n",
      "Epoch 833/1000\n",
      "1649/1649 [==============================] - 0s 197us/step - loss: 0.3277 - acc: 0.9278 - val_loss: 0.3859 - val_acc: 0.8983\n",
      "Epoch 834/1000\n",
      "1649/1649 [==============================] - 0s 181us/step - loss: 0.3274 - acc: 0.9266 - val_loss: 0.3842 - val_acc: 0.9007\n",
      "Epoch 835/1000\n",
      "1649/1649 [==============================] - 0s 207us/step - loss: 0.3275 - acc: 0.9254 - val_loss: 0.3841 - val_acc: 0.9007\n",
      "Epoch 836/1000\n",
      "1649/1649 [==============================] - 0s 185us/step - loss: 0.3271 - acc: 0.9266 - val_loss: 0.3853 - val_acc: 0.8959\n",
      "Epoch 837/1000\n",
      "1649/1649 [==============================] - 0s 174us/step - loss: 0.3266 - acc: 0.9260 - val_loss: 0.3846 - val_acc: 0.8983\n",
      "Epoch 838/1000\n",
      "1649/1649 [==============================] - 0s 188us/step - loss: 0.3266 - acc: 0.9260 - val_loss: 0.3849 - val_acc: 0.8983\n",
      "Epoch 839/1000\n",
      "1649/1649 [==============================] - 0s 170us/step - loss: 0.3265 - acc: 0.9284 - val_loss: 0.3857 - val_acc: 0.8983\n",
      "Epoch 840/1000\n",
      "1649/1649 [==============================] - 0s 185us/step - loss: 0.3263 - acc: 0.9266 - val_loss: 0.3842 - val_acc: 0.8983\n",
      "Epoch 841/1000\n",
      "1649/1649 [==============================] - 0s 203us/step - loss: 0.3260 - acc: 0.9254 - val_loss: 0.3836 - val_acc: 0.9007\n",
      "Epoch 842/1000\n",
      "1649/1649 [==============================] - 0s 198us/step - loss: 0.3262 - acc: 0.9254 - val_loss: 0.3839 - val_acc: 0.8983\n",
      "Epoch 843/1000\n",
      "1649/1649 [==============================] - 0s 196us/step - loss: 0.3260 - acc: 0.9266 - val_loss: 0.3830 - val_acc: 0.9007\n",
      "Epoch 844/1000\n",
      "1649/1649 [==============================] - 0s 219us/step - loss: 0.3256 - acc: 0.9260 - val_loss: 0.3836 - val_acc: 0.8983\n",
      "Epoch 845/1000\n",
      "1649/1649 [==============================] - 0s 197us/step - loss: 0.3253 - acc: 0.9278 - val_loss: 0.3826 - val_acc: 0.9007\n",
      "Epoch 846/1000\n",
      "1649/1649 [==============================] - 0s 204us/step - loss: 0.3251 - acc: 0.9266 - val_loss: 0.3830 - val_acc: 0.8983\n",
      "Epoch 847/1000\n",
      "1649/1649 [==============================] - 0s 197us/step - loss: 0.3255 - acc: 0.9266 - val_loss: 0.3835 - val_acc: 0.8983\n",
      "Epoch 848/1000\n",
      "1649/1649 [==============================] - 0s 203us/step - loss: 0.3248 - acc: 0.9303 - val_loss: 0.3828 - val_acc: 0.9007\n",
      "Epoch 849/1000\n",
      "1649/1649 [==============================] - 0s 192us/step - loss: 0.3248 - acc: 0.9260 - val_loss: 0.3816 - val_acc: 0.9007\n",
      "Epoch 850/1000\n",
      "1649/1649 [==============================] - 0s 196us/step - loss: 0.3245 - acc: 0.9278 - val_loss: 0.3820 - val_acc: 0.9007\n",
      "Epoch 851/1000\n",
      "1649/1649 [==============================] - 0s 256us/step - loss: 0.3241 - acc: 0.9297 - val_loss: 0.3820 - val_acc: 0.8983\n",
      "Epoch 852/1000\n",
      "1649/1649 [==============================] - 0s 181us/step - loss: 0.3240 - acc: 0.9272 - val_loss: 0.3827 - val_acc: 0.8983\n",
      "Epoch 853/1000\n",
      "1649/1649 [==============================] - 0s 254us/step - loss: 0.3238 - acc: 0.9260 - val_loss: 0.3829 - val_acc: 0.8983\n",
      "Epoch 854/1000\n",
      "1649/1649 [==============================] - 0s 276us/step - loss: 0.3236 - acc: 0.9290 - val_loss: 0.3816 - val_acc: 0.9007\n",
      "Epoch 855/1000\n",
      "1649/1649 [==============================] - 0s 244us/step - loss: 0.3234 - acc: 0.9284 - val_loss: 0.3817 - val_acc: 0.9007\n",
      "Epoch 856/1000\n",
      "1649/1649 [==============================] - 0s 223us/step - loss: 0.3235 - acc: 0.9290 - val_loss: 0.3819 - val_acc: 0.9007\n",
      "Epoch 857/1000\n",
      "1649/1649 [==============================] - 0s 239us/step - loss: 0.3231 - acc: 0.9278 - val_loss: 0.3811 - val_acc: 0.9007\n",
      "Epoch 858/1000\n",
      "1649/1649 [==============================] - 0s 241us/step - loss: 0.3232 - acc: 0.9260 - val_loss: 0.3806 - val_acc: 0.9007\n",
      "Epoch 859/1000\n",
      "1649/1649 [==============================] - 0s 214us/step - loss: 0.3231 - acc: 0.9278 - val_loss: 0.3821 - val_acc: 0.9007\n",
      "Epoch 860/1000\n",
      "1649/1649 [==============================] - 0s 189us/step - loss: 0.3225 - acc: 0.9290 - val_loss: 0.3802 - val_acc: 0.9007\n",
      "Epoch 861/1000\n",
      "1649/1649 [==============================] - 0s 215us/step - loss: 0.3225 - acc: 0.9266 - val_loss: 0.3798 - val_acc: 0.9007\n",
      "Epoch 862/1000\n",
      "1649/1649 [==============================] - 0s 186us/step - loss: 0.3226 - acc: 0.9266 - val_loss: 0.3802 - val_acc: 0.9007\n",
      "Epoch 863/1000\n",
      "1649/1649 [==============================] - 0s 186us/step - loss: 0.3220 - acc: 0.9284 - val_loss: 0.3805 - val_acc: 0.9007\n",
      "Epoch 864/1000\n",
      "1649/1649 [==============================] - 0s 183us/step - loss: 0.3226 - acc: 0.9284 - val_loss: 0.3804 - val_acc: 0.9007\n",
      "Epoch 865/1000\n",
      "1649/1649 [==============================] - 0s 188us/step - loss: 0.3222 - acc: 0.9272 - val_loss: 0.3802 - val_acc: 0.9007\n",
      "Epoch 866/1000\n",
      "1649/1649 [==============================] - 0s 178us/step - loss: 0.3218 - acc: 0.9278 - val_loss: 0.3798 - val_acc: 0.9007\n",
      "Epoch 867/1000\n",
      "1649/1649 [==============================] - 0s 192us/step - loss: 0.3214 - acc: 0.9284 - val_loss: 0.3804 - val_acc: 0.8983\n",
      "Epoch 868/1000\n",
      "1649/1649 [==============================] - 0s 193us/step - loss: 0.3211 - acc: 0.9290 - val_loss: 0.3800 - val_acc: 0.9007\n",
      "Epoch 869/1000\n",
      "1649/1649 [==============================] - 0s 170us/step - loss: 0.3211 - acc: 0.9297 - val_loss: 0.3784 - val_acc: 0.9007\n",
      "Epoch 870/1000\n",
      "1649/1649 [==============================] - 0s 187us/step - loss: 0.3212 - acc: 0.9278 - val_loss: 0.3777 - val_acc: 0.9007\n",
      "Epoch 871/1000\n",
      "1649/1649 [==============================] - 0s 175us/step - loss: 0.3207 - acc: 0.9284 - val_loss: 0.3790 - val_acc: 0.9007\n",
      "Epoch 872/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1649/1649 [==============================] - 0s 175us/step - loss: 0.3205 - acc: 0.9284 - val_loss: 0.3792 - val_acc: 0.8983\n",
      "Epoch 873/1000\n",
      "1649/1649 [==============================] - 0s 179us/step - loss: 0.3204 - acc: 0.9290 - val_loss: 0.3781 - val_acc: 0.8983\n",
      "Epoch 874/1000\n",
      "1649/1649 [==============================] - 0s 188us/step - loss: 0.3202 - acc: 0.9284 - val_loss: 0.3791 - val_acc: 0.9007\n",
      "Epoch 875/1000\n",
      "1649/1649 [==============================] - 0s 192us/step - loss: 0.3204 - acc: 0.9309 - val_loss: 0.3785 - val_acc: 0.9007\n",
      "Epoch 876/1000\n",
      "1649/1649 [==============================] - 0s 175us/step - loss: 0.3200 - acc: 0.9278 - val_loss: 0.3769 - val_acc: 0.9007\n",
      "Epoch 877/1000\n",
      "1649/1649 [==============================] - 0s 176us/step - loss: 0.3196 - acc: 0.9297 - val_loss: 0.3773 - val_acc: 0.9007\n",
      "Epoch 878/1000\n",
      "1649/1649 [==============================] - 0s 184us/step - loss: 0.3196 - acc: 0.9284 - val_loss: 0.3802 - val_acc: 0.8983\n",
      "Epoch 879/1000\n",
      "1649/1649 [==============================] - 0s 173us/step - loss: 0.3192 - acc: 0.9278 - val_loss: 0.3780 - val_acc: 0.9007\n",
      "Epoch 880/1000\n",
      "1649/1649 [==============================] - 0s 174us/step - loss: 0.3191 - acc: 0.9303 - val_loss: 0.3786 - val_acc: 0.8983\n",
      "Epoch 881/1000\n",
      "1649/1649 [==============================] - 0s 189us/step - loss: 0.3192 - acc: 0.9297 - val_loss: 0.3783 - val_acc: 0.8983\n",
      "Epoch 882/1000\n",
      "1649/1649 [==============================] - 0s 189us/step - loss: 0.3187 - acc: 0.9297 - val_loss: 0.3772 - val_acc: 0.9007\n",
      "Epoch 883/1000\n",
      "1649/1649 [==============================] - 0s 176us/step - loss: 0.3188 - acc: 0.9297 - val_loss: 0.3765 - val_acc: 0.9007\n",
      "Epoch 884/1000\n",
      "1649/1649 [==============================] - 0s 177us/step - loss: 0.3185 - acc: 0.9303 - val_loss: 0.3775 - val_acc: 0.8983\n",
      "Epoch 885/1000\n",
      "1649/1649 [==============================] - 0s 175us/step - loss: 0.3178 - acc: 0.9303 - val_loss: 0.3763 - val_acc: 0.9031\n",
      "Epoch 886/1000\n",
      "1649/1649 [==============================] - 0s 187us/step - loss: 0.3178 - acc: 0.9266 - val_loss: 0.3763 - val_acc: 0.9031\n",
      "Epoch 887/1000\n",
      "1649/1649 [==============================] - 0s 175us/step - loss: 0.3177 - acc: 0.9278 - val_loss: 0.3765 - val_acc: 0.9007\n",
      "Epoch 888/1000\n",
      "1649/1649 [==============================] - 0s 184us/step - loss: 0.3179 - acc: 0.9309 - val_loss: 0.3760 - val_acc: 0.9007\n",
      "Epoch 889/1000\n",
      "1649/1649 [==============================] - 0s 192us/step - loss: 0.3178 - acc: 0.9284 - val_loss: 0.3749 - val_acc: 0.9007\n",
      "Epoch 890/1000\n",
      "1649/1649 [==============================] - 0s 174us/step - loss: 0.3175 - acc: 0.9303 - val_loss: 0.3760 - val_acc: 0.9007\n",
      "Epoch 891/1000\n",
      "1649/1649 [==============================] - 0s 212us/step - loss: 0.3171 - acc: 0.9290 - val_loss: 0.3762 - val_acc: 0.9031\n",
      "Epoch 892/1000\n",
      "1649/1649 [==============================] - 0s 224us/step - loss: 0.3170 - acc: 0.9309 - val_loss: 0.3762 - val_acc: 0.9007\n",
      "Epoch 893/1000\n",
      "1649/1649 [==============================] - 0s 197us/step - loss: 0.3169 - acc: 0.9297 - val_loss: 0.3754 - val_acc: 0.9007\n",
      "Epoch 894/1000\n",
      "1649/1649 [==============================] - 0s 220us/step - loss: 0.3171 - acc: 0.9278 - val_loss: 0.3739 - val_acc: 0.9007\n",
      "Epoch 895/1000\n",
      "1649/1649 [==============================] - 0s 228us/step - loss: 0.3168 - acc: 0.9272 - val_loss: 0.3746 - val_acc: 0.9007\n",
      "Epoch 896/1000\n",
      "1649/1649 [==============================] - 0s 178us/step - loss: 0.3162 - acc: 0.9315 - val_loss: 0.3764 - val_acc: 0.9007\n",
      "Epoch 897/1000\n",
      "1649/1649 [==============================] - 0s 196us/step - loss: 0.3161 - acc: 0.9290 - val_loss: 0.3754 - val_acc: 0.9031\n",
      "Epoch 898/1000\n",
      "1649/1649 [==============================] - 0s 202us/step - loss: 0.3161 - acc: 0.9315 - val_loss: 0.3751 - val_acc: 0.9031\n",
      "Epoch 899/1000\n",
      "1649/1649 [==============================] - 0s 196us/step - loss: 0.3157 - acc: 0.9278 - val_loss: 0.3746 - val_acc: 0.9031\n",
      "Epoch 900/1000\n",
      "1649/1649 [==============================] - 0s 197us/step - loss: 0.3159 - acc: 0.9278 - val_loss: 0.3730 - val_acc: 0.9007\n",
      "Epoch 901/1000\n",
      "1649/1649 [==============================] - 0s 209us/step - loss: 0.3159 - acc: 0.9303 - val_loss: 0.3730 - val_acc: 0.9007\n",
      "Epoch 902/1000\n",
      "1649/1649 [==============================] - 0s 264us/step - loss: 0.3154 - acc: 0.9297 - val_loss: 0.3742 - val_acc: 0.9007\n",
      "Epoch 903/1000\n",
      "1649/1649 [==============================] - 0s 281us/step - loss: 0.3150 - acc: 0.9309 - val_loss: 0.3759 - val_acc: 0.8983\n",
      "Epoch 904/1000\n",
      "1649/1649 [==============================] - 0s 263us/step - loss: 0.3150 - acc: 0.9315 - val_loss: 0.3746 - val_acc: 0.9007\n",
      "Epoch 905/1000\n",
      "1649/1649 [==============================] - 0s 206us/step - loss: 0.3152 - acc: 0.9297 - val_loss: 0.3726 - val_acc: 0.9007\n",
      "Epoch 906/1000\n",
      "1649/1649 [==============================] - 0s 236us/step - loss: 0.3146 - acc: 0.9309 - val_loss: 0.3731 - val_acc: 0.9007\n",
      "Epoch 907/1000\n",
      "1649/1649 [==============================] - 0s 222us/step - loss: 0.3143 - acc: 0.9309 - val_loss: 0.3732 - val_acc: 0.9031\n",
      "Epoch 908/1000\n",
      "1649/1649 [==============================] - 0s 190us/step - loss: 0.3146 - acc: 0.9321 - val_loss: 0.3738 - val_acc: 0.9007\n",
      "Epoch 909/1000\n",
      "1649/1649 [==============================] - 0s 176us/step - loss: 0.3141 - acc: 0.9290 - val_loss: 0.3732 - val_acc: 0.9007\n",
      "Epoch 910/1000\n",
      "1649/1649 [==============================] - 0s 188us/step - loss: 0.3142 - acc: 0.9321 - val_loss: 0.3723 - val_acc: 0.9007\n",
      "Epoch 911/1000\n",
      "1649/1649 [==============================] - 0s 173us/step - loss: 0.3136 - acc: 0.9303 - val_loss: 0.3740 - val_acc: 0.8983\n",
      "Epoch 912/1000\n",
      "1649/1649 [==============================] - 0s 183us/step - loss: 0.3137 - acc: 0.9303 - val_loss: 0.3732 - val_acc: 0.9007\n",
      "Epoch 913/1000\n",
      "1649/1649 [==============================] - 0s 186us/step - loss: 0.3138 - acc: 0.9290 - val_loss: 0.3725 - val_acc: 0.9007\n",
      "Epoch 914/1000\n",
      "1649/1649 [==============================] - 0s 212us/step - loss: 0.3131 - acc: 0.9333 - val_loss: 0.3725 - val_acc: 0.9031\n",
      "Epoch 915/1000\n",
      "1649/1649 [==============================] - 0s 226us/step - loss: 0.3134 - acc: 0.9290 - val_loss: 0.3710 - val_acc: 0.9007\n",
      "Epoch 916/1000\n",
      "1649/1649 [==============================] - 0s 211us/step - loss: 0.3129 - acc: 0.9309 - val_loss: 0.3714 - val_acc: 0.9007\n",
      "Epoch 917/1000\n",
      "1649/1649 [==============================] - 0s 234us/step - loss: 0.3126 - acc: 0.9303 - val_loss: 0.3719 - val_acc: 0.9031\n",
      "Epoch 918/1000\n",
      "1649/1649 [==============================] - 0s 224us/step - loss: 0.3128 - acc: 0.9309 - val_loss: 0.3724 - val_acc: 0.9007\n",
      "Epoch 919/1000\n",
      "1649/1649 [==============================] - 0s 261us/step - loss: 0.3129 - acc: 0.9309 - val_loss: 0.3711 - val_acc: 0.8983\n",
      "Epoch 920/1000\n",
      "1649/1649 [==============================] - 0s 207us/step - loss: 0.3126 - acc: 0.9315 - val_loss: 0.3706 - val_acc: 0.9031\n",
      "Epoch 921/1000\n",
      "1649/1649 [==============================] - 0s 243us/step - loss: 0.3120 - acc: 0.9315 - val_loss: 0.3716 - val_acc: 0.9031\n",
      "Epoch 922/1000\n",
      "1649/1649 [==============================] - 0s 206us/step - loss: 0.3127 - acc: 0.9303 - val_loss: 0.3711 - val_acc: 0.9007\n",
      "Epoch 923/1000\n",
      "1649/1649 [==============================] - 0s 223us/step - loss: 0.3120 - acc: 0.9303 - val_loss: 0.3694 - val_acc: 0.9007\n",
      "Epoch 924/1000\n",
      "1649/1649 [==============================] - 0s 233us/step - loss: 0.3116 - acc: 0.9327 - val_loss: 0.3711 - val_acc: 0.9031\n",
      "Epoch 925/1000\n",
      "1649/1649 [==============================] - 0s 209us/step - loss: 0.3114 - acc: 0.9290 - val_loss: 0.3702 - val_acc: 0.9007\n",
      "Epoch 926/1000\n",
      "1649/1649 [==============================] - 0s 234us/step - loss: 0.3116 - acc: 0.9339 - val_loss: 0.3702 - val_acc: 0.9007\n",
      "Epoch 927/1000\n",
      "1649/1649 [==============================] - 0s 238us/step - loss: 0.3112 - acc: 0.9309 - val_loss: 0.3711 - val_acc: 0.9031\n",
      "Epoch 928/1000\n",
      "1649/1649 [==============================] - 0s 224us/step - loss: 0.3109 - acc: 0.9309 - val_loss: 0.3706 - val_acc: 0.9031\n",
      "Epoch 929/1000\n",
      "1649/1649 [==============================] - 0s 218us/step - loss: 0.3107 - acc: 0.9327 - val_loss: 0.3704 - val_acc: 0.9031\n",
      "Epoch 930/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1649/1649 [==============================] - 0s 204us/step - loss: 0.3104 - acc: 0.9309 - val_loss: 0.3702 - val_acc: 0.9007\n",
      "Epoch 931/1000\n",
      "1649/1649 [==============================] - 0s 187us/step - loss: 0.3107 - acc: 0.9315 - val_loss: 0.3707 - val_acc: 0.9007\n",
      "Epoch 932/1000\n",
      "1649/1649 [==============================] - 0s 200us/step - loss: 0.3102 - acc: 0.9303 - val_loss: 0.3697 - val_acc: 0.9007\n",
      "Epoch 933/1000\n",
      "1649/1649 [==============================] - 0s 197us/step - loss: 0.3102 - acc: 0.9327 - val_loss: 0.3686 - val_acc: 0.9031\n",
      "Epoch 934/1000\n",
      "1649/1649 [==============================] - 0s 181us/step - loss: 0.3100 - acc: 0.9315 - val_loss: 0.3697 - val_acc: 0.9007\n",
      "Epoch 935/1000\n",
      "1649/1649 [==============================] - 0s 190us/step - loss: 0.3098 - acc: 0.9321 - val_loss: 0.3700 - val_acc: 0.9007\n",
      "Epoch 936/1000\n",
      "1649/1649 [==============================] - 0s 191us/step - loss: 0.3099 - acc: 0.9333 - val_loss: 0.3696 - val_acc: 0.8983\n",
      "Epoch 937/1000\n",
      "1649/1649 [==============================] - 0s 193us/step - loss: 0.3096 - acc: 0.9327 - val_loss: 0.3695 - val_acc: 0.9031\n",
      "Epoch 938/1000\n",
      "1649/1649 [==============================] - 0s 200us/step - loss: 0.3091 - acc: 0.9327 - val_loss: 0.3683 - val_acc: 0.9031\n",
      "Epoch 939/1000\n",
      "1649/1649 [==============================] - 0s 204us/step - loss: 0.3091 - acc: 0.9333 - val_loss: 0.3694 - val_acc: 0.9007\n",
      "Epoch 940/1000\n",
      "1649/1649 [==============================] - 0s 208us/step - loss: 0.3089 - acc: 0.9303 - val_loss: 0.3690 - val_acc: 0.9031\n",
      "Epoch 941/1000\n",
      "1649/1649 [==============================] - 0s 203us/step - loss: 0.3087 - acc: 0.9339 - val_loss: 0.3691 - val_acc: 0.9031\n",
      "Epoch 942/1000\n",
      "1649/1649 [==============================] - 0s 196us/step - loss: 0.3085 - acc: 0.9309 - val_loss: 0.3679 - val_acc: 0.9031\n",
      "Epoch 943/1000\n",
      "1649/1649 [==============================] - 0s 211us/step - loss: 0.3086 - acc: 0.9290 - val_loss: 0.3681 - val_acc: 0.9031\n",
      "Epoch 944/1000\n",
      "1649/1649 [==============================] - 0s 226us/step - loss: 0.3084 - acc: 0.9321 - val_loss: 0.3682 - val_acc: 0.9031\n",
      "Epoch 945/1000\n",
      "1649/1649 [==============================] - 0s 199us/step - loss: 0.3086 - acc: 0.9315 - val_loss: 0.3665 - val_acc: 0.9007\n",
      "Epoch 946/1000\n",
      "1649/1649 [==============================] - 0s 203us/step - loss: 0.3080 - acc: 0.9339 - val_loss: 0.3670 - val_acc: 0.9031\n",
      "Epoch 947/1000\n",
      "1649/1649 [==============================] - 0s 243us/step - loss: 0.3082 - acc: 0.9309 - val_loss: 0.3665 - val_acc: 0.9031\n",
      "Epoch 948/1000\n",
      "1649/1649 [==============================] - 0s 244us/step - loss: 0.3076 - acc: 0.9303 - val_loss: 0.3672 - val_acc: 0.9031\n",
      "Epoch 949/1000\n",
      "1649/1649 [==============================] - 0s 260us/step - loss: 0.3080 - acc: 0.9321 - val_loss: 0.3667 - val_acc: 0.9056\n",
      "Epoch 950/1000\n",
      "1649/1649 [==============================] - 0s 257us/step - loss: 0.3076 - acc: 0.9315 - val_loss: 0.3666 - val_acc: 0.9031\n",
      "Epoch 951/1000\n",
      "1649/1649 [==============================] - 0s 255us/step - loss: 0.3076 - acc: 0.9315 - val_loss: 0.3676 - val_acc: 0.9031\n",
      "Epoch 952/1000\n",
      "1649/1649 [==============================] - 0s 244us/step - loss: 0.3073 - acc: 0.9309 - val_loss: 0.3658 - val_acc: 0.9007\n",
      "Epoch 953/1000\n",
      "1649/1649 [==============================] - 0s 231us/step - loss: 0.3071 - acc: 0.9327 - val_loss: 0.3669 - val_acc: 0.9031\n",
      "Epoch 954/1000\n",
      "1649/1649 [==============================] - 0s 215us/step - loss: 0.3069 - acc: 0.9333 - val_loss: 0.3673 - val_acc: 0.9007\n",
      "Epoch 955/1000\n",
      "1649/1649 [==============================] - 0s 216us/step - loss: 0.3069 - acc: 0.9315 - val_loss: 0.3667 - val_acc: 0.9031\n",
      "Epoch 956/1000\n",
      "1649/1649 [==============================] - 0s 198us/step - loss: 0.3070 - acc: 0.9309 - val_loss: 0.3670 - val_acc: 0.9007\n",
      "Epoch 957/1000\n",
      "1649/1649 [==============================] - 0s 246us/step - loss: 0.3067 - acc: 0.9290 - val_loss: 0.3651 - val_acc: 0.9007\n",
      "Epoch 958/1000\n",
      "1649/1649 [==============================] - 0s 240us/step - loss: 0.3065 - acc: 0.9321 - val_loss: 0.3652 - val_acc: 0.9007\n",
      "Epoch 959/1000\n",
      "1649/1649 [==============================] - 0s 200us/step - loss: 0.3060 - acc: 0.9339 - val_loss: 0.3668 - val_acc: 0.8983\n",
      "Epoch 960/1000\n",
      "1649/1649 [==============================] - 0s 227us/step - loss: 0.3061 - acc: 0.9321 - val_loss: 0.3656 - val_acc: 0.9031\n",
      "Epoch 961/1000\n",
      "1649/1649 [==============================] - 0s 213us/step - loss: 0.3056 - acc: 0.9303 - val_loss: 0.3639 - val_acc: 0.9007\n",
      "Epoch 962/1000\n",
      "1649/1649 [==============================] - 0s 212us/step - loss: 0.3053 - acc: 0.9333 - val_loss: 0.3663 - val_acc: 0.9007\n",
      "Epoch 963/1000\n",
      "1649/1649 [==============================] - 0s 256us/step - loss: 0.3057 - acc: 0.9315 - val_loss: 0.3647 - val_acc: 0.9056\n",
      "Epoch 964/1000\n",
      "1649/1649 [==============================] - 0s 238us/step - loss: 0.3054 - acc: 0.9315 - val_loss: 0.3644 - val_acc: 0.9007\n",
      "Epoch 965/1000\n",
      "1649/1649 [==============================] - 0s 232us/step - loss: 0.3053 - acc: 0.9303 - val_loss: 0.3653 - val_acc: 0.9031\n",
      "Epoch 966/1000\n",
      "1649/1649 [==============================] - 0s 275us/step - loss: 0.3049 - acc: 0.9339 - val_loss: 0.3641 - val_acc: 0.8983\n",
      "Epoch 967/1000\n",
      "1649/1649 [==============================] - 0s 230us/step - loss: 0.3050 - acc: 0.9309 - val_loss: 0.3655 - val_acc: 0.9007\n",
      "Epoch 968/1000\n",
      "1649/1649 [==============================] - 0s 240us/step - loss: 0.3046 - acc: 0.9345 - val_loss: 0.3649 - val_acc: 0.9031\n",
      "Epoch 969/1000\n",
      "1649/1649 [==============================] - 0s 239us/step - loss: 0.3044 - acc: 0.9345 - val_loss: 0.3628 - val_acc: 0.9007\n",
      "Epoch 970/1000\n",
      "1649/1649 [==============================] - 0s 206us/step - loss: 0.3045 - acc: 0.9327 - val_loss: 0.3635 - val_acc: 0.8983\n",
      "Epoch 971/1000\n",
      "1649/1649 [==============================] - 0s 224us/step - loss: 0.3042 - acc: 0.9339 - val_loss: 0.3646 - val_acc: 0.9031\n",
      "Epoch 972/1000\n",
      "1649/1649 [==============================] - 0s 204us/step - loss: 0.3041 - acc: 0.9309 - val_loss: 0.3642 - val_acc: 0.9007\n",
      "Epoch 973/1000\n",
      "1649/1649 [==============================] - 0s 202us/step - loss: 0.3038 - acc: 0.9339 - val_loss: 0.3634 - val_acc: 0.9031\n",
      "Epoch 974/1000\n",
      "1649/1649 [==============================] - 0s 257us/step - loss: 0.3037 - acc: 0.9297 - val_loss: 0.3632 - val_acc: 0.9031\n",
      "Epoch 975/1000\n",
      "1649/1649 [==============================] - 0s 198us/step - loss: 0.3037 - acc: 0.9357 - val_loss: 0.3634 - val_acc: 0.9056\n",
      "Epoch 976/1000\n",
      "1649/1649 [==============================] - 0s 198us/step - loss: 0.3032 - acc: 0.9339 - val_loss: 0.3632 - val_acc: 0.9031\n",
      "Epoch 977/1000\n",
      "1649/1649 [==============================] - 0s 252us/step - loss: 0.3032 - acc: 0.9345 - val_loss: 0.3621 - val_acc: 0.9007\n",
      "Epoch 978/1000\n",
      "1649/1649 [==============================] - 0s 220us/step - loss: 0.3031 - acc: 0.9369 - val_loss: 0.3637 - val_acc: 0.9007\n",
      "Epoch 979/1000\n",
      "1649/1649 [==============================] - 0s 223us/step - loss: 0.3028 - acc: 0.9327 - val_loss: 0.3627 - val_acc: 0.9031\n",
      "Epoch 980/1000\n",
      "1649/1649 [==============================] - 0s 212us/step - loss: 0.3029 - acc: 0.9321 - val_loss: 0.3618 - val_acc: 0.9031\n",
      "Epoch 981/1000\n",
      "1649/1649 [==============================] - 0s 238us/step - loss: 0.3024 - acc: 0.9321 - val_loss: 0.3625 - val_acc: 0.9031\n",
      "Epoch 982/1000\n",
      "1649/1649 [==============================] - 0s 228us/step - loss: 0.3027 - acc: 0.9333 - val_loss: 0.3617 - val_acc: 0.9031\n",
      "Epoch 983/1000\n",
      "1649/1649 [==============================] - 0s 198us/step - loss: 0.3027 - acc: 0.9345 - val_loss: 0.3630 - val_acc: 0.9031\n",
      "Epoch 984/1000\n",
      "1649/1649 [==============================] - 0s 206us/step - loss: 0.3022 - acc: 0.9327 - val_loss: 0.3623 - val_acc: 0.9031\n",
      "Epoch 985/1000\n",
      "1649/1649 [==============================] - 0s 209us/step - loss: 0.3023 - acc: 0.9357 - val_loss: 0.3628 - val_acc: 0.9007\n",
      "Epoch 986/1000\n",
      "1649/1649 [==============================] - 0s 199us/step - loss: 0.3023 - acc: 0.9327 - val_loss: 0.3627 - val_acc: 0.9007\n",
      "Epoch 987/1000\n",
      "1649/1649 [==============================] - 0s 200us/step - loss: 0.3016 - acc: 0.9351 - val_loss: 0.3609 - val_acc: 0.9031\n",
      "Epoch 988/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1649/1649 [==============================] - 0s 181us/step - loss: 0.3017 - acc: 0.9327 - val_loss: 0.3618 - val_acc: 0.9031\n",
      "Epoch 989/1000\n",
      "1649/1649 [==============================] - 0s 200us/step - loss: 0.3018 - acc: 0.9321 - val_loss: 0.3620 - val_acc: 0.9031\n",
      "Epoch 990/1000\n",
      "1649/1649 [==============================] - 0s 215us/step - loss: 0.3011 - acc: 0.9321 - val_loss: 0.3612 - val_acc: 0.9031\n",
      "Epoch 991/1000\n",
      "1649/1649 [==============================] - 0s 240us/step - loss: 0.3013 - acc: 0.9351 - val_loss: 0.3609 - val_acc: 0.9007\n",
      "Epoch 992/1000\n",
      "1649/1649 [==============================] - 0s 247us/step - loss: 0.3010 - acc: 0.9339 - val_loss: 0.3619 - val_acc: 0.9031\n",
      "Epoch 993/1000\n",
      "1649/1649 [==============================] - 0s 248us/step - loss: 0.3012 - acc: 0.9327 - val_loss: 0.3609 - val_acc: 0.9056\n",
      "Epoch 994/1000\n",
      "1649/1649 [==============================] - 0s 202us/step - loss: 0.3004 - acc: 0.9333 - val_loss: 0.3611 - val_acc: 0.9007\n",
      "Epoch 995/1000\n",
      "1649/1649 [==============================] - 0s 227us/step - loss: 0.3008 - acc: 0.9333 - val_loss: 0.3595 - val_acc: 0.9007\n",
      "Epoch 996/1000\n",
      "1649/1649 [==============================] - 0s 229us/step - loss: 0.3008 - acc: 0.9339 - val_loss: 0.3609 - val_acc: 0.9031\n",
      "Epoch 997/1000\n",
      "1649/1649 [==============================] - 0s 206us/step - loss: 0.3003 - acc: 0.9363 - val_loss: 0.3601 - val_acc: 0.8983\n",
      "Epoch 998/1000\n",
      "1649/1649 [==============================] - 0s 189us/step - loss: 0.3000 - acc: 0.9357 - val_loss: 0.3600 - val_acc: 0.9031\n",
      "Epoch 999/1000\n",
      "1649/1649 [==============================] - 0s 207us/step - loss: 0.3002 - acc: 0.9315 - val_loss: 0.3586 - val_acc: 0.9031\n",
      "Epoch 1000/1000\n",
      "1649/1649 [==============================] - 0s 196us/step - loss: 0.2997 - acc: 0.9351 - val_loss: 0.3611 - val_acc: 0.9056\n"
     ]
    }
   ],
   "source": [
    "hist = model_final.fit(x=new_X_train, y=y_train, epochs= 1000, validation_data= (new_X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox  6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history[\"acc\"])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=40, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "traindata = datagen.flow(new_X_train, y_train, batch_size=len(X_train))\n",
    "testdata = datagen.flow(new_X_test, y_test, batch_size=len(X_test))\n",
    "\n",
    "# traindata = datagen.flow(X_train, y_train)\n",
    "# testdata = datagen.flow(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist = model_final.fit_generator(generator= traindata, steps_per_epoch= 2, epochs= 100, validation_data= testdata, validation_steps=1, callbacks=[checkpoint,early])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
